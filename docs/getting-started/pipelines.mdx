# Quick Start: Pipelines

This chapter will help you get started with configuring and running pipelines, walking you through a common scenario. The pipeline processes Syslog messages and forwards them to Microsoft Sentinel in the Advanced Security Information Model (ASIM) format.

:::note
For a general discussion, see our [overview](/docs/configuration/pipelines/index.mdx) chapter.
:::

## Overview

We'll create a pipeline that ingests logs from a Syslog source, processes them, and forwards them to Microsoft Sentinel in ASIM format.

## Prerequisites

To achieve this goal, we must have an environment with access to Syslog inputs. We also need a **Microsoft Sentinel** workspace with proper permissions.

Also, a basic understanding of the YAML format is necessary to carry out the configuration tasks.

## Step 1: Configure the Syslog Device

First, let's create a Syslog input device to receive log data. Create a file named `devices.yml` with the following entries:

```yml
- id: 1
  name: syslog_server
  description: "Syslog server for security logs"
  type: syslog
  tags:
    - security
    - network
  properties:
    protocol: tcp
    port: 1514
    framing: delimiter
    line_delimiter: "\n"
    buffer_size: 16384
    batch_size: 1000
```

This configuration will create a TCP Syslog server listening on port `1514`. You will use the newline character as a delimiter for message framing. You have also set the appropriate buffer and batch sizes. The tags you have entered are optional but may be helpful.

## Step 2: Configure the Microsoft Sentinel ASIM Target

Next, create a target for **Microsoft Sentinel** in a file named `targets.yml`:

```yml
- id: 1
  name: sentinel_asim
  description: "Microsoft Sentinel ASIM target"
  type: sentinel
  properties:
    tenant_id: "${AZURE_TENANT_ID}"
    client_id: "${AZURE_CLIENT_ID}"
    client_secret: "${AZURE_CLIENT_SECRET}"
    workspace_id: "${SENTINEL_WORKSPACE_ID}"
    format: asim
    batch_size: 100
    flush_interval: 60
```

With this configuration, you are setting up the authentication with **Azure** using environment variables. You have specified the target format as ASIM, and configured batching and flush intervals for optimal performance.

## Step 3: Create a Processing Pipeline

Now, let's create a pipeline that processes _Syslog_ data and transforms it into the ASIM format. Create a file named `pipeline.yml` and place it under `<vm_root>`:

```yml
- id: 1
  name: syslog_to_sentinel
  description: "Process Syslog data for Microsoft Sentinel ASIM"
  processors:
    # Parse Syslog header information
    - grok:
        - field: message
        - patterns:
            - "%{SYSLOGBASE} %{GREEDYDATA:syslog.message}"
    
    # Extract authentication events
    - grok:
        - field: syslog.message
        - patterns:
            - "%{DATA:event.action} %{WORD:user.name} from %{IP:source.ip}"
        - ignore_failure: true
    
    # Set event metadata
    - set:
        - field: event.kind
        - value: event
    
    # Set event category based on program
    - script:
        - lang: golang
        - source: |
            package main
            
            func main() {
              if program, ok := logEntry["program"].(string); ok {
                switch program {
                case "sshd":
                  setField(logEntry, "event.category", []string{"authentication"})
                case "firewalld":
                  setField(logEntry, "event.category", []string{"network"})
                default:
                  setField(logEntry, "event.category", []string{"process"})
                }
              }
            }
    
    # Map fields to ASIM schema
    - rename:
        - fields:
            - from: timestamp
              to: event.created
            - from: source.ip
              to: src.ip
            - from: user.name
              to: user.name_orig
    
    # Clean up temporary fields
    - remove:
        - field:
            - syslog.message
            - message
        - ignore_missing: true
```

This pipeline parses the _Syslog_ header information using the `grok` processors. It then extracts authentication event details, and sets the common event metadata. Next, using a script, it categorizes the events based on the program, and maps the fields to the ASIM schema structure. Finally, it cleans up temporary fields.

You have also specified to ignore the missing fields in order to avoid raising an exception.

## Step 4: Configure the Route

Finally, create a route to connect the Syslog device to the pipeline and Microsoft Sentinel target. Create a file named `routes.yml`:

```yml
- name: syslog_to_sentinel_route
  description: "Route Syslog data to Microsoft Sentinel ASIM"
  sources:
    - name: syslog_server
  pipeline: syslog_to_sentinel
  destinations:
    - name: sentinel_asim
```

This route configuration connects the Syslog server as the source, applies the `syslog_to_sentinel` pipeline for processing, and sends the processed data to the **Microsoft Sentinel** ASIM target.

## Complete Example

Let's put it all together. Your file structure should look like:

```
config/
├── devices.yml
├── targets.yml
├── pipelines.yml
└── routes.yml
```

## Verification

To verify your configuration:

1. Start your server with the configuration files
2. Send test Syslog messages to port **1514**
3. Check the logs for any errors
4. Verify in **Microsoft Sentinel** that data is being received in the ASIM format

## Troubleshooting

If you encounter issues:

- Check that your Syslog server is receiving messages (network connectivity)
- Verify that your **Microsoft Sentinel** credentials are correct
- Examine the processor logs for any failures in the pipeline
- Ensure the mapped fields match the ASIM schema requirements

## Next Steps

Now that you have a basic pipeline running, consider:

- Adding more complex field mappings for specific log types
- Implementing additional processors for data enrichment
- Creating multiple pipelines for different Syslog sources
- Configuring alerts or dashboards in Microsoft Sentinel based on your data

With these building blocks, you can create sophisticated log processing workflows tailored to your security monitoring needs.
