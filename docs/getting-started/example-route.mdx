# Example: Basic Routing

This chapter will help you get started with routes to forward data to specific destinations, walking you through common scenarios.

## Prerequisites

:::note
Before configuring routes, verify that the pipelines and targets to be used in the routes are already configured and accessible.

See the introductory chapters for configuring [targets](/docs/getting-started/example-target.mdx) and [pipelines](/docs/getting-started/example-pipeline.mdx).
:::

The simplest route that can be configured only relays the data as is:

```yaml
routes:
  - name: basic_forward
    description: "Forward all logs to storage"
    targets:
      - name: storage
```

Here, we are forwarding the raw data to a previously configured target named `storage`.

## Using Pipelines

A route can use a pipeline as part of its forwarding process.

We can have a single pipeline:

```yaml
routes:
  - name: process_logs
    description: "Process and store logs"
    pipelines:
      - name: normalize_logs
    targets:
      - name: storage
```

This configuration will [normalize](/docs/configuration/pipelines/normalization.mdx) the data before sending it to the target named `storage`.

We can also use several pipelines consecutively:

```yaml
routes:
  - name: complex_processing
    description: "Multi-stage processing"
    pipelines:
      - name: normalize
      - name: enrich
      - name: aggregate
    targets:
      - name: analytics
```

The specified 3 pipelines will be used for purposes that should be obvious from their names: normalizing, enriching, and aggregating. The data will then be routed to a target used for analytics.

## Selection

Since the routing operation occurs amidst high telemetry traffic, pipelines can also be used to selectively process specific data streams.

This can be done using device types:

```yaml
routes:
  - name: syslog_route
    if: device.type == 'syslog'
    pipelines:
      - name: syslog_normalize
    targets:
      - name: syslog_storage

  - name: windows_route
    if: device.type == 'windows'
    pipelines:
      - name: windows_normalize
    targets:
      - name: windows_storage
```

This route will collect two streams of data from a _syslog_ device and a _windows_ device, normalize them using the specific pipelines of each, and then direct them to their respective targets.

The selection can also be done using datasets:

```yaml
routes:
  - name: security_dataset
    if: dataset.name == 'security_logs'
    pipelines:
      - name: security_process
    targets:
      - name: security_analytics

  - name: performance_dataset
    if: dataset.name == 'performance_metrics'
    pipelines:
      - name: metrics_process
    targets:
      - name: metrics_platform
```

The first route will collect data from a dataset used for security logs, whereas the second from another one used for performance metrics.

## Forwarding

The same data can be sent to multiple targets, a technique known as _mirroring_:

```yaml
routes:
  - name: mirror_logs
    description: "Store logs in multiple locations"
    pipelines:
      - name: normalize
    targets:
      - name: primary_storage
      - name: backup_storage
      - name: analytics_platform
```

Here, the data will be received by 3 different targets: a primary and a backup storage, and an analytics platform.

## Conditionals

The filtering required for selecting the data for a route can be done using conditional statements, as seen from some of the examples above. The conditions can be as simple as picking a specific device type:

```yaml
routes:
  - name: firewall_logs
    description: "Process firewall logs"
    if: device.type == 'firewall'
    pipelines:
      - name: firewall_pipeline
    targets:
      - name: security_storage
```

Or they can be complex, drilling down to the attributes of the data to be collected such as severity of security breaches, date range of the data collected, etc.:

```yaml
routes:
  - name: critical_errors
    if: log.severity == 'critical' && log.date >= '2024.05.01'
    pipelines:
      - name: urgent_process
    targets:
      - name: alerts
      - name: storage
```

This route will collect critical errors that have occurred after a certain date, and will forward them to two separate targets.

## Monitoring

Once we configure our route, we can monitor the stream it will generate using the command line.

{/* TODO: Complete */}

## Optimizing

{/* TODO: Complete */}
