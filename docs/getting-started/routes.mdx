---
sidebar_label: "Routes"
---

# Getting Started: Routes

This chapter will help you get started with routes to forward data to specific destinations, walking you through common scenarios.

## Configuration Files

{/* TODO: Where do we put the YAML files? */}

The simplest route that can be configured only relays the data:

```yaml
routes:
  - name: basic_forward
    description: "Forward all logs to storage"
    targets:
      - name: storage
```

Here, we are forwarding the raw data to a previously configured target named `storage`. (For an introduction to configuring targets, see [this chapter](/docs/getting-started/targets.mdx).)

## Using Pipelines

A route can use a pipeline as part of its forwarding process. (See [this chapter](/docs/getting-started/pipelines.mdx) for introductory information on configuring pipelines.)

We can have a single pipeline:

```yaml
routes:
  - name: process_logs
    description: "Process and store logs"
    pipelines:
      - name: normalize_logs
    targets:
      - name: storage
```

This configuration is intended to normalize the data before sending it to the target named `storage`. (See [normalization](/docs/configuration/pipelines/normalization.mdx) for details.)

We can also use several pipelines:

```yaml
routes:
  - name: complex_processing
    description: "Multi-stage processing"
    pipelines:
      - name: normalize
      - name: enrich
      - name: aggregate
    targets:
      - name: analytics
```

This time we are using 3 different pipelines whose purposes should be obvious from their names: normalizing, enriching, and aggregating.

## Selection

Since the routing operation is in the middle of a telemetry traffic, we can also use pipelines for the purpose of selecting specific types of data.

This can be done using device types:

```yaml
routes:
  - name: syslog_route
    if: device.type == 'syslog'
    pipelines:
      - name: syslog_normalize
    targets:
      - name: syslog_storage

  - name: windows_route
    if: device.type == 'windows'
    pipelines:
      - name: windows_normalize
    targets:
      - name: windows_storage
```

Our route collects data from a _syslog_ device and a _windows_ device, normalizes them using their own pipelines, and then directs it to their respective targets.

The selection can also be done using datasets:

```yaml
routes:
  - name: security_dataset
    if: dataset.name == 'security_logs'
    pipelines:
      - name: security_process
    targets:
      - name: security_analytics

  - name: performance_dataset
    if: dataset.name == 'performance_metrics'
    pipelines:
      - name: metrics_process
    targets:
      - name: metrics_platform
```

Our first route collects data from a dataset used for security logs, and the second one from another dataset used for performance metrics.

## Forwarding

The same data can be sent to multiple targets, which is known as _mirroring_:

```yaml
routes:
  - name: mirror_logs
    description: "Store logs in multiple locations"
    pipelines:
      - name: normalize
    targets:
      - name: primary_storage
      - name: backup_storage
      - name: analytics_platform
```

The data here is received by three different targets: a primary and a backup storage, plus an analytics platform.

## Conditionals

The filtering required for selecting the data for a route can be done using conditional statements, as seen from some of the examples above. The conditions can be as simple as picking a specific device type:

```yaml
routes:
  - name: firewall_logs
    description: "Process firewall logs"
    if: device.type == 'firewall'
    pipelines:
      - name: firewall_pipeline
    targets:
      - name: security_storage
```

Or they can be complex, drilling down to the attributes of the data collected such as severity of a security breach, the date range of the data collected, etc.:

```yaml
routes:
  - name: critical_errors
    if: log.severity == 'critical' && log.date >= '2024.05.01'
    pipelines:
      - name: urgent_process
    targets:
      - name: alerts
      - name: storage
```

When designing routes, verify that the conditions are correctly expressed, that the pipelines are configured, and that the targets are accessible. Also, monitor the route's metrics to optimize it if necessary.

## Optimization

{/* TODO: Enter optimization examples */}
