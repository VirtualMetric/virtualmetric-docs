---
pagination_next: null
---

# Example: A Syslog-To-Sentinel Data Pipeline

This chapter will help you get started with configuring and running a pipeline, walking you through a common scenario.

## Overview

Pipelines are used to grab data from producers, reshape them with [processors](/docs/configuration/pipelines/processors/index.mdx), and then send them to consumers.

:::note
For a general discussion, see the [overview](/docs/configuration/pipelines/index.mdx).
:::

Here, we will create a pipeline that ingests logs from a _Syslog_ source, selects certain items and categorizes them, and forwards them to **Microsoft Sentinel** in _Advanced Security Information Model_ (ASIM) format.

We will implement the following scenario:

|Step|Purpose|
|---|---|
|Create a `syslog` device|Define the parameters of a listener to grab messages from a source. See the fields available in the [Syslog](/docs/appendix.mdx#syslog) format|
|Create a `sentinel` target|Define the format for sending the messages to a destination. See the fields available in the [ASIM](/docs/appendix.mdx#asim) format|
|Define processors|Grab the `message` and `syslog.message` fields using the `grok` processor, and map them to ASIM fields for routing|
|Define a route|Specify the source, the destination, and the pipeline to be used|

## Prerequisites

We must work in an environment that has access to _Syslog_ messages. We also need a **Microsoft Sentinel** workspace with proper permissions.

Also, a basic understanding of the YAML format will be helpful for configuring the files.

## Configuration Files

By default, these reside in a directory under the `config` folder and have a `.yml` extension:

```powershell
├───config
│   ├───devices
│   │       syslog.yml
│   │
│   ├───routes
│   │       default.yml
│   │
│   └───targets
│           console.yml
│           file.yml
```

You can place your configuration files anywhere you wish under `config` since **Director** discovers them by traversing the subdirectories recursively.

Your primary pipeline configuration file may be, e.g.

* `<vm_root>/config/pipeline.yml`
* `<vm_root>/config/pipelines/syslog-to-sentinel.yml`
* `<vm_root>/config/pipelines/syslog-to-sentinel/messages.yml`

As the nesting level increases, file names become more specific, offering additional context for classification. Select the organizational method that best meets your requirements.

Pick the organization that best fits your needs.

For convenience, we will place all our configurations in a single file name `pipeline.yml`  and place it directly under `config`.

:::tip
When configuring the pipeline, devices are referred to with their `id` parameter, whereas targets, routes, and other pipelines are referred to with the identifiers used in their `name` parameters.
:::

## Step 1: Configure The Device

First, we have to define a device that will receive the log data. We will use the configuration we have created in our [device example](/docs/getting-started/example-device.mdx) as our starting point, modifying it as fits our needs:

```yml
- id: 1
  name: syslog_tcp
  type: syslog
  properties:
    protocol: tcp
    port: 1514
    framing: delimiter
    line_delimiter: "\n"
    buffer_size: 16384
    batch_size: 1000
```

Put this device configuration in our file.

This configuration will create a _TCP Syslog_ server listening on port `1514`. We have specfied the line feed character as the delimiter for message framing. We also set the appropriate buffer and batch sizes.

## Step 2: Configure The Target

Next, we will define a target for **Microsoft Sentinel** in our file, again using the configuration we have created in our [target example](/docs/getting-started/example-target.mdx) as the basis:

```yml
- id: 1
  name: sentinel_asim
  description: "Microsoft Sentinel ASIM target"
  type: sentinel
  properties:
    tenant_id: "${AZURE_TENANT_ID}"
    client_id: "${AZURE_CLIENT_ID}"
    client_secret: "${AZURE_CLIENT_SECRET}"
    workspace_id: "${SENTINEL_WORKSPACE_ID}"
    format: asim
    batch_size: 100
    flush_interval: 60
```

With this configuration, we are setting up the authentication with **Azure** using environment variables. We have specified the target format as ASIM, and configured batching and flush intervals for optimal performance.

## Step 3: Create A Processing Pipeline

We are now ready to configure our pipeline. Put the following in our configuration file:

```yml
- id: 1
  name: syslog_to_sentinel
  description: "Process Syslog data for Microsoft Sentinel ASIM"
  processors:
    # Parse Syslog header information
    - grok:
        field: message
        patterns:
          - "%{SYSLOGBASE} %{GREEDYDATA:syslog.message}"
    
    # Extract authentication events
    - grok:
        field: syslog.message
        patterns:
          - "%{DATA:event.action} %{WORD:user.name} from %{IP:source.ip}"
        gnore_failure: true
    
    # Set event metadata
    - set:
        field: event.kind
        value: event
    
    # Set event category based on mail
    - script:
        lang: golang
        source: |
          package main
          
          func main() {
            if program, ok := logEntry["program"].(string); ok {
              switch program {
              case "sshd":
                setField(logEntry, "event.category", []string{"authentication"})
              case "firewall":
                setField(logEntry, "event.category", []string{"network"})
              default:
                setField(logEntry, "event.category", []string{"process"})
              }
            }
          }
    
    # Map fields to ASIM schema
    - rename:
        fields:
          - from: timestamp
            to: event.created
          - from: source.ip
            to: src.ip
          - from: user.name
            to: user.name_orig
    
    # Clean up temporary fields
    - remove:
        field:
          - syslog.message
          - message
        ignore_missing: true
```

This configuration will

* parse the _Syslog_ header information using the `grok` processor&mdash;reading the fields `syslog.message`, `event.action`, `user.name`, and `source.ip`&mdash;and will extract authentication event details

* set the common event metadata `event.kind`

* using a script, categorize the events based on the type of `program` generating the log&mdash; as `authentication`, `network`, or `process`&mdash;and map the fields to the ASIM schema structure

* clean up the temporary fields.

:::note
To avoid raising an exception, we chose to ignore the missing fields.
:::

## Step 4: Configure the Route

Finally, we have to create a route to connect our device to the pipeline and then to our target. Put the following definition in our configuration file:

```yml
- name: syslog_to_sentinel_route
  description: "Route Syslog data to Microsoft Sentinel ASIM"
  sources:
    - name: syslog_server
  pipeline: syslog_to_sentinel
  destinations:
    - name: sentinel_asim
```

This configuration will connect to the _Syslog_ server as the source, apply the `syslog_to_sentinel` pipeline for processing the ingested data, and then send that data to the **Microsoft Sentinel** ASIM target we have specified.

## Monitoring

Let's put it all together: we have defined a device and a target, configured a pipeline to specify how the data will be processed, and specified a route that will use this pipeline. At this point we have everything ready.

We will now run our pipeline and see the results:

<Tabs groupId="os-options">
  <TabItem value="windows" label="Windows">
    ```PowerShell
    .\vmetric-director -mode=pipeline -name=syslog_to_sentinel
    ```
  </TabItem>
  <TabItem value="linux" label="Linux">
    ```bash
    ./vmetric-director -mode=pipeline -name=syslog_to_sentinel
    ```
  </TabItem>
  <TabItem value="macos" label="macOS">
    ```bash
    ./vmetric-director -mode=pipeline -name=syslog_to_sentinel
    ```
  </TabItem>
</Tabs>

:::note
We can use the name we have specified for our pipeline to run it. All we have to do is use the `mode` parameter to tell **Director** that we will run a "pipeline", and then `name` it on the CLI.
:::

After we call **Director** with our configuration file, it should send test _Syslog_ messages to port **1514**. Check the logs for any errors, and verify in **Microsoft Sentinel** that data is being received in the ASIM format.

## Troubleshooting

If you encounter any issues, check the following:

* Syslog server should be receiving messages (network connectivity)
* **Microsoft Sentinel** credentials should be correct

Also, examine the processor logs for any failures in the pipeline, and ensure that the mapped fields match the ASIM schema requirements.

## Next Steps

Now that you have a basic pipeline running, consider:

- Adding more complex field mappings for specific log types
- Implementing additional processors for data enrichment
- Creating multiple pipelines for different _Syslog_ sources
- Configuring alerts or dashboards in **Microsoft Sentinel** based on your data

With these building blocks, you can create sophisticated log processing workflows tailored to your security monitoring needs.

{/* TODO: Review and update the configuration details if necessary. */}
