# Cloudflare R2

<span className="theme-doc-version-badge badge badge--secondary">Cloudflare</span><span className="theme-doc-version-badge badge badge--secondary">Long Term Storage</span>

## Synopsis

Creates a target that writes log messages to Cloudflare R2 buckets with support for various file formats and authentication methods. The target handles large file uploads efficiently with configurable rotation based on size or event count. Cloudflare R2 provides zero egress fees and S3-compatible object storage.

## Schema

```yaml {1,3}
- name: <string>
  description: <string>
  type: cloudflarer2
  pipelines: <pipeline[]>
  status: <boolean>
  properties:
    key: <string>
    secret: <string>
    region: <string>
    endpoint: <string>
    part_size: <numeric>
    bucket: <string>
    buckets:
      - bucket: <string>
        name: <string>
        format: <string>
        compression: <string>
        extension: <string>
        schema: <string>
    name: <string>
    format: <string>
    compression: <string>
    extension: <string>
    schema: <string>
    max_size: <numeric>
    batch_size: <numeric>
    timeout: <numeric>
    field_format: <string>
    interval: <string|numeric>
    cron: <string>
    debug:
      status: <boolean>
      dont_send_logs: <boolean>
```

## Configuration

The following fields are used to define the target:

|Field|Required|Default|Description|
|---|---|---|---|
|`name`|Y||Target name|
|`description`|N|-|Optional description|
|`type`|Y||Must be `cloudflarer2`|
|`pipelines`|N|-|Optional post-processor pipelines|
|`status`|N|`true`|Enable/disable the target|

### Cloudflare R2 Credentials

|Field|Required|Default|Description|
|---|---|---|---|
|`key`|Y|-|Cloudflare R2 access key ID|
|`secret`|Y|-|Cloudflare R2 secret access key|
|`region`|N|`auto`|R2 region (typically `auto` for automatic region selection)|
|`endpoint`|Y|-|R2 endpoint URL (format: `https://<account-id>.r2.cloudflarestorage.com`)|

### Connection

|Field|Required|Default|Description|
|---|---|---|---|
|`part_size`|N|`5`|Multipart upload part size in megabytes (minimum 5MB)|
|`timeout`|N|`30`|Connection timeout in seconds|
|`field_format`|N|-|Data normalization format. See applicable <Topic id="normalization-mapping">Normalization</Topic> section|

### Files

|Field|Required|Default|Description|
|---|---|---|---|
|`bucket`|N*|-|Default R2 bucket name (used if `buckets` not specified)|
|`buckets`|N*|-|Array of bucket configurations for file distribution|
|`buckets.bucket`|Y|-|R2 bucket name|
|`buckets.name`|Y|-|File name template|
|`buckets.format`|N|`"json"`|Output format: `json`, `multijson`, `avro`, `parquet`|
|`buckets.compression`|N|`"zstd"`|Compression algorithm|
|`buckets.extension`|N|Matches `format`|File extension override|
|`buckets.schema`|N*|-|Schema definition file path (required for Avro and Parquet formats)|
|`name`|N|`"vmetric.{{.Timestamp}}.{{.Extension}}"`|Default file name template when `buckets` not used|
|`format`|N|`"json"`|Default output format when `buckets` not used|
|`compression`|N|`"zstd"`|Default compression when `buckets` not used|
|`extension`|N|Matches `format`|Default file extension when `buckets` not used|
|`schema`|N|-|Default schema path when `buckets` not used|
|`max_size`|N|`0`|Maximum file size in bytes before rotation|
|`batch_size`|N|`100000`|Maximum number of messages per file|

\* = Either `bucket` or `buckets` must be specified. When using `buckets`, schema is conditionally required for Avro and Parquet formats.

:::note
When `max_size` is reached, the current file is uploaded to R2 and a new file is created. For unlimited file size, set the field to `0`.
:::

### Scheduler

|Field|Required|Default|Description|
|---|---|---|---|
|`interval`|N|realtime|Execution frequency. See <Topic id="interval">Interval</Topic> for details|
|`cron`|N|-|Cron expression for scheduled execution. See <Topic id="cron">Cron</Topic> for details|

### Debug Options

|Field|Required|Default|Description|
|---|---|---|---|
|`debug.status`|N|`false`|Enable debug logging|
|`debug.dont_send_logs`|N|`false`|Process logs but don't send to target (testing)|

## Details

The Cloudflare R2 target provides enterprise-grade cloud storage integration with zero egress fees and comprehensive file format support. R2 is Cloudflare's object storage service designed for high-performance data storage with global accessibility.

### Authentication

Requires R2 access credentials obtained from the Cloudflare dashboard. Access keys are scoped to specific accounts and can be restricted to individual buckets for enhanced security.

### Endpoint Configuration

The endpoint URL follows the pattern `https://<account-id>.r2.cloudflarestorage.com` where `<account-id>` is your Cloudflare account identifier found in the R2 dashboard.

### File Formats

|Format|Description|
|---|---|
|`json`|Each log entry is written as a separate JSON line (JSONL format)|
|`multijson`|All log entries are written as a single JSON array|
|`avro`|Apache Avro format with schema|
|`parquet`|Apache Parquet columnar format with schema|

### Compression

All formats support optional compression to reduce storage costs and transfer times. Compression is applied before upload.

|Format|Compression Options|
|---|---|
|JSON/MultiJSON|`zstd` (default), `gzip`|
|Avro|`null`, `deflate`, `snappy`, `zstd`|
|Parquet|`uncompressed`, `gzip`, `snappy`, `zstd`, `brotli`, `lz4`|

### File Management

Files are rotated based on size (`max_size` parameter) or event count (`batch_size` parameter), whichever limit is reached first. Template variables in file names enable dynamic file naming for time-based partitioning.

### Templates

The following template variables can be used in file names:

|Variable|Description|Example|
|---|---|---|
|`{{.Year}}`|Current year|`2024`|
|`{{.Month}}`|Current month|`01`|
|`{{.Day}}`|Current day|`15`|
|`{{.Timestamp}}`|Current timestamp in nanoseconds|`1703688533123456789`|
|`{{.Format}}`|File format|`json`|
|`{{.Extension}}`|File extension|`json`|
|`{{.Compression}}`|Compression type|`zstd`|
|`{{.TargetName}}`|Target name|`my_logs`|
|`{{.TargetType}}`|Target type|`cloudflarer2`|
|`{{.Table}}`|Bucket name|`logs`|

### Multipart Upload

Large files automatically use multipart upload protocol with configurable part size (`part_size` parameter). Default 5MB part size balances upload efficiency and memory usage.

### Multiple Buckets

Single target can write to multiple R2 buckets with different configurations, enabling data distribution strategies (e.g., raw data to one bucket, processed data to another).

### Schema Requirements

Avro and Parquet formats require schema definition files. Schema files must be accessible at the path specified in the `schema` parameter during target initialization.

### Cost Advantages

Cloudflare R2 provides zero egress fees, making it cost-effective for frequently accessed data and analytics workloads that require regular data retrieval.

## Examples

### Basic Configuration

The minimum configuration for a JSON R2 target:

```yaml
targets:
  - name: basic_r2
    type: cloudflarer2
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      bucket: "datastream-logs"
```

### Multiple Buckets

Configuration for distributing data across multiple R2 buckets with different formats:

```yaml
targets:
  - name: multi_bucket_export
    type: cloudflarer2
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      buckets:
        - bucket: "raw-data-archive"
          name: "raw-{{.Year}}-{{.Month}}-{{.Day}}.json"
          format: "multijson"
          compression: "gzip"
        - bucket: "analytics-data"
          name: "analytics-{{.Year}}/{{.Month}}/{{.Day}}/data_{{.Timestamp}}.parquet"
          format: "parquet"
          schema: "<schema definition>"
          compression: "snappy"
```

### Parquet Format

Configuration for daily partitioned Parquet files:

```yaml
targets:
  - name: parquet_analytics
    type: cloudflarer2
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      bucket: "analytics-lake"
      name: "events/year={{.Year}}/month={{.Month}}/day={{.Day}}/part-{{.Timestamp}}.parquet"
      format: "parquet"
      schema: "<schema definition>"
      compression: "snappy"
      max_size: 536870912
```

### High Reliability

Configuration with enhanced settings:

```yaml
targets:
  - name: reliable_r2
    type: cloudflarer2
    pipelines:
      - checkpoint
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      bucket: "critical-logs"
      name: "logs-{{.Timestamp}}.json"
      format: "json"
      timeout: 60
      part_size: 10
```

### With Field Normalization

Using field normalization for standard format:

```yaml
targets:
  - name: normalized_r2
    type: cloudflarer2
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      bucket: "normalized-logs"
      name: "logs-{{.Timestamp}}.json"
      format: "json"
      field_format: "cim"
```

### Debug Configuration

Configuration with debugging enabled:

```yaml
targets:
  - name: debug_r2
    type: cloudflarer2
    properties:
      key: "4f3e2a1b0c9d8e7f6a5b4c3d2e1f0a9b"
      secret: "9b8a7c6d5e4f3a2b1c0d9e8f7a6b5c4d3e2f1a0b"
      endpoint: "https://abc123def456.r2.cloudflarestorage.com"
      region: "auto"
      bucket: "test-logs"
      name: "test-{{.Timestamp}}.json"
      format: "json"
      debug:
        status: true
        dont_send_logs: true
```