---
pagination_prev: null
sidebar_label: Overview
---

# Configuration: Overview

In order to create its telemetry pipelines, **DataStream** uses five key components: **Devices**, **Targets**, **Pipelines**, **Processors**, and **Routes**. Configuration involves handling and managing text-based structured files (_YAML_) that specify values for various settings required for running these components.

The various stages where these components are used and how they connect to each other can be described schematically as:

<blockquote style={{textAlign: "center"}}>
**Ingest** [_Source_<sub>1</sub>, _Source_<sub>2</sub>, &#8230;, _Source_<sub>n</sub>]<br/>
&darr;<br/>
**Preprocess** (Normalize) &map; **Route** [_Enrich_ &compfn; _Transform_ &compfn; _Select_] &map; **Postprocess** (Normalize)<br/>
&darr;<br/>
**Forward** [_Destination_<sub>1</sub>, _Destination_<sub>2</sub>, &#8230;, _Destination_<sub>n</sub>]
</blockquote>

* To ingest data from _Sources_ and to communicate with them, **DataStream** uses **Devices** which are listeners. Each dedicated device type is conformant with the layout of a specific log data generator.

* For the **Preprocessing**, **Routing**, and **Postprocessing** stages, **DataStream** uses **Pipelines** which are sequential arrangements of **Processors**, i.e. functions that handle and transform data stored in various fields for a wide variety of purposes. (They also help normalize data for the purposes of either transformation or enrichment as well as storage.)

* To forward processed data to _Destinations_ and to communicate with them, **DataStream** uses **Targets** which are senders. Each dedicated target type is conformant with the layout of a specific log data receiver.

By using these dedicated components, you can design powerful and efficient telemetry systems very elegantly. You only need to understand how they work, how they interact, and how they can be configured and combined to achieve your objectives.

## Managing YAML Files

The most fundamental tools you use to design your telemetry streams are YAML files.

To implement the logic of the components that will define and run the processes of the above-mentioned stages, **DataStream** uses YAML-based configuration files.

These can be found in some of the folders under its root directory, here indicated with `<vm_root>`:

```powershell
<vm_root>
│   vmetric.yml
├───config
│   ├───devices
│   │       estreamer.yml
│   │       syslog.yml
│   │       tcp.yml
│   ├───routes
│   │       default.yml
│   └───targets
│           console.yml
│           file.yml
├───package
│   └───definitions
│       └───pipelines
│               checkpoint.yml
│               cisco.yml
│               normalize.yml
└───user
    └───definitions
        └───pipelines
                checkpoint.yml
                normalize.yml
```

All management tasks related to running the telemetry operation are carried out using these files.

By default, these files are placed in folders according to their component types. They contain predefined fields that the components recognize, and **DataStream** uses the setting values in these fields to spawn and run its processes.

* Two directories are of importance: `package` and `user`.

  The `package` directory contains templates and ready-to-use definitions. These definitions are updated with newer versions of **Director**.

  :::warning
  Never modify the definition files under `package` directly. To create a configuration using one of these as a template, copy the relevant file to the corresponding location under `user` first, and then edit it.
  :::

  The `user` directory contains custom configurations. These definitions take precedence over those under the `package` directory. The definitions here are preserved between updates.

* The configurations may be placed in separate files or they may be grouped together logically, i.e. based on their intended purpose of use or the type of data streams they process. By default, these files reside in the directories under the `config` folder.

  :::tip
  You can place your files anywhere you wish under the `config` directory. **Director** discovers all of them by traversing the folders recursively.
  :::

  To illustrate, a target configuration file can be named as, e.g.

  <Tabs>
    <TabItem value="powershell" label="PowerShell" default>
      ```powershell
      C:\Path\To\<vm_root>\config\target.yml
      ```

      -or-

      ```powershell
      C:\Path\To\<vm_root>\config\targets\outputs.yml
      ```

      -or-

      ```powershell
      C:\Path\To\<vm_root>\config\targets\outputs\sentinel.yml
      ```
    </TabItem>
    <TabItem value="bash" label="Bash">
      ```bash
      /usr/bin/path/to/<vm_root>/config/target.yml
      ```

      -or-

      ```bash
      /usr/bin/path/to/<vm_root>/config/targets/outputs.yml
      ```

      -or-

      ```bash
      /usr/bin/path/to/<vm_root>/config/targets/outputs/sentinel.yml
      ```
    </TabItem>
  </Tabs>

  As the nesting level increases, the file names become more specific, offering additional context for classification.

  Select the organizational style that best suits your needs.

## General Format

All components follow a consistent YAML structure that emphasizes readability and maintainability:

:::warning[attention]
Configurations must conform to [**these syntactic rules**](../appendix.mdx#configuration-bnf).

The **Overview** sections of the component types summarize their common fields under the **Configuration** heading. 

The **Schema** paragraphs of specific component sections provide their fields.
:::

All components have properties&mdash;i.e. YAML fields with parameters&mdash;that define their specific behavior. Some of these are mandatory and must be present in every component.

A few are worth mentioning since they are frequently used:

* **Identification** - Every component requires unique identification:

  ```yaml
  - id: 1                   # Numeric identifier
    name: example_component # Human-readable name
  ```

* **Status Control** - Components can be enabled or disabled:

  ```yaml
  - id: 1
    name: example_component
    status: true  # Enables this component
  ```

* **Environment Variables** - Sensitive information can be stored in system variables:

  ```yaml
  properties:
    username: admin
    password: ${SECRET_PASSWORD}  # References environment variable
  ```

* **Tagging** - Components can be tagged for better organization, and&mdash;optionally&mdash;a description can be used to document its purpose:

  ```yaml
  - id: 1
    name: example_component
    description: "Optional detailed explanation" # Documentation
    tags:
      - production  # For quick search
      - security
  ```

### Data Flow

**DataStream** implements a modular architecture of components working together to create complete data flows. The following example illustrates a security monitoring flow:

**Example**: Assume we have a route named `critical_security` defined like so:

```yaml
routes:
  - name: critical_security
    devices:
      - name: firewall_logs
    if: "event.severity == 'critical'"
    pipelines:
      - name: security_enrichment
    targets:
      - name: security_elasticsearch
      - name: security_team_notification
```

This route refers to:

- a device named `firewall_logs`:

    ```yaml
    devices:
      - id: 1
        name: firewall_logs
        type: syslog
        properties:
          port: 514
    ```

- a pipeline named `security_enrichment`:

    ```yaml
    pipelines:
      - name: security_enrichment
        processors:
          - grok:
              field: message
              patterns:
                - "%{CISCOFW106001}"
          - set:
              field: event.category
              value: security
          - geoip:
              field: source.ip
              target_field: source.geo
    ```

- and two targets named `security_elasticsearch` and `security_team_notification` respectively:

    ```yaml
    targets:
      - name: security_elasticsearch
        type: elasticsearch
        properties:
          url: "https://es.example.com:9200"
          index: "security-%{+yyyy.MM.dd}"
      - name: security_team_notification
        type: webhook
        properties:
          url: "https://alerts.example.com/security"
          method: POST
    ```

This configuration is intended to do the following:

* the device collects firewall logs from _Syslog_ that have _critical_ status

* the pipeline selects (via the `grok` processor) _Cisco_ events, categorizes them as security events, and enriches them by adding their _source IP_ and _geographic location_

* the targets forward the events curated to _Elasticsearch_ and a notification system for a security team

### Validation

Before deploying your configuration, check it using the available tools. The validator checks for syntactic correctness, required field presence, reference integrity, and logical consistency.

- Check the configuration file

  <Tabs>
    <TabItem value="powershell" label="PowerShell" default>
      ```powershell
      vmetric -validate -c critical_security.yml
      ```
    </TabItem>
    <TabItem value="bash" label="Bash">
      ```bash
      vmetric -validate -c critical_security.yml
      ```
    </TabItem>
  </Tabs>

- Test configuration with sample data

  <Tabs>
    <TabItem value="powershell" label="PowerShell" default>
      ```powershell
      vmetric -test -c critical_security.yml -i sample-data.json
      ```
    </TabItem>
    <TabItem value="bash" label="Bash">
      ```bash
      vmetric -test -c critical_security.yml -i sample-data.json
      ```
    </TabItem>
  </Tabs>

:::tip
Refer to specific component documentation for detailed options.
:::
