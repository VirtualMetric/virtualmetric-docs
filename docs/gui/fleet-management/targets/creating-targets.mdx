# Creating Targets

This guide covers the comprehensive target creation process, from initial configuration through final deployment, including specific setup procedures for Azure Sentinel, file outputs, database connections, and other target types.

## Target Creation Workflow

### Step 1: General Information

Begin target creation with essential identification and type selection:

**Basic Target Properties:**
- **Target name**: Unique identifier for the target configuration within your DataStream environment
- **Target type**: Selection from available output types (Sentinel, File, Database, Console, Cloud Storage)
- **Description**: Optional documentation for target purpose, usage, and operational context
- **Environment tags**: Categorization for development, staging, or production use for organized management

**Target Type Selection Considerations:**
- **Data Destination**: Choose the appropriate target type based on where data needs to be delivered
- **Performance Requirements**: Consider throughput and latency requirements for target selection
- **Security Needs**: Evaluate security and compliance requirements for different target types
- **Integration Requirements**: Assess integration capabilities with existing systems and workflows

### Step 2: Target-Specific Configuration

The second step provides configuration options tailored to your selected target type, with different interfaces and requirements based on the target selection.

#### Azure Sentinel Configuration

Azure Sentinel targets require specific Azure integration parameters:

**Configuration State Management:**
The Azure properties configuration interface operates in two states:

**Disabled State:**
- Configuration fields are disabled before target type selection is completed
- Prevents incomplete configuration and ensures proper setup sequence
- Provides guidance on prerequisite steps for Azure integration
- Shows placeholder information for required configuration elements

**Enabled State:**
When Azure Sentinel is selected as the target type, the configuration interface activates with:

**Azure Subscription Settings:**
- **Subscription ID**: Azure subscription identifier for resource access
- **Resource Group**: Specific resource group containing the Log Analytics workspace
- **Tenant Information**: Azure Active Directory tenant configuration
- **Region Selection**: Azure region for data residency and compliance requirements

**Authentication Configuration:**
- **Service Principal**: Service principal credentials for automated authentication
- **Managed Identity**: Azure managed identity configuration for secure, credential-free access
- **Certificate Authentication**: SSL/TLS certificate management for secure connections
- **Multi-Factor Authentication**: MFA configuration when required by organizational policies

**Workspace Integration:**
- **Log Analytics Workspace**: Direct integration with specific Log Analytics workspace
- **Workspace ID**: Unique identifier for the target Log Analytics workspace
- **Connection Strings**: Secure connection strings for data transmission
- **Data Collection Endpoints**: Configuration of data collection endpoints for optimal performance

**Security and Compliance:**
- **Encryption Settings**: In-transit and at-rest encryption configuration
- **Access Controls**: Role-based access control (RBAC) configuration
- **Audit Logging**: Configuration of audit logging for compliance requirements
- **Data Retention**: Data retention policies aligned with organizational and regulatory requirements

### Step 3: Stream Configuration

Configure data stream mappings and routing for the target with flexible options for different data processing approaches:

#### Automatic Stream Configuration

The automatic configuration option provides intelligent stream detection and routing:

**Automatic Detection Features:**
- **System-Identified Streams**: Automatic identification of available data streams
- **Recommended Routing**: System-generated recommendations for optimal data routing
- **Default Mappings**: Pre-configured field mappings for common use cases
- **Performance Optimization**: Automatically optimized settings for throughput and reliability

**Benefits of Automatic Configuration:**
- **Simplified Setup**: Reduced configuration complexity for standard deployments
- **Best Practices**: Built-in best practices for data routing and processing
- **Quick Deployment**: Faster time-to-production for standard configurations
- **Reduced Errors**: Minimized configuration errors through automated setup

#### Manual Stream Configuration

Manual configuration provides complete control over stream routing and processing:

**Custom Stream Mapping:**
- **Selective Stream Assignment**: Choose specific data streams for target delivery
- **Custom Routing Rules**: Define complex routing logic based on data content and metadata
- **Conditional Processing**: Set up conditional rules for different data types and sources
- **Priority Configuration**: Assign priorities to different data streams for processing order

**Advanced Processing Options:**

**Filtering Configuration:**
- **Include/Exclude Rules**: Define specific criteria for data inclusion or exclusion
- **Content-Based Filtering**: Filter data based on content analysis and pattern matching
- **Metadata Filtering**: Use metadata attributes for filtering decisions
- **Dynamic Filtering**: Configure filters that adapt based on system conditions

**Format Options:**
- **Output Format Selection**: Choose from JSON, CEF, LEEF, XML, or custom formats
- **Field Mapping**: Map source fields to target-specific field names and structures
- **Data Transformation**: Apply transformations for data enrichment and standardization
- **Compression Configuration**: Set up compression options for network efficiency

**Batch Processing Settings:**
- **Batch Size Configuration**: Optimize batch sizes for target performance characteristics
- **Buffering Parameters**: Configure buffering strategies for reliability and performance
- **Retry Logic**: Set up retry mechanisms for handling temporary failures
- **Error Handling**: Define behavior for permanent failures and data quality issues

#### Installation Success Confirmation

Upon successful target creation, the system provides comprehensive confirmation:

**Success Indicators:**
- **Confirmation status**: Target successfully configured and operational
- **Connection validation**: Initial connectivity test results with performance metrics
- **Configuration summary**: Complete review of all configured settings and options
- **Next steps**: Guidance for additional configuration, monitoring setup, and optimization

**Post-Creation Validation:**
- **Connectivity Testing**: Automated tests to verify target accessibility and functionality
- **Data Flow Verification**: Confirmation that data can flow successfully to the target
- **Performance Baseline**: Initial performance measurements for ongoing monitoring
- **Health Check Setup**: Configuration of ongoing health monitoring and alerting

## Target-Specific Creation Processes

### Azure Sentinel Target Creation

Azure Sentinel targets require specific attention to Azure integration details:

**Prerequisites:**
- **Azure Subscription**: Active Azure subscription with appropriate permissions
- **Log Analytics Workspace**: Pre-existing Log Analytics workspace or permissions to create one
- **Service Principal**: Service principal with appropriate permissions for data ingestion
- **Network Connectivity**: Connectivity between DataStream and Azure services

**Configuration Best Practices:**
- **Security Configuration**: Use least-privilege access principles for service principal configuration
- **Regional Alignment**: Choose Azure regions that align with data residency requirements
- **Workspace Organization**: Organize Log Analytics workspaces for optimal data management
- **Monitoring Setup**: Configure monitoring for Azure Sentinel target health and performance

### Database Target Creation

Database targets require specific connection and performance configuration:

**Connection Configuration:**
- **Database Type**: Selection of specific database platform (SQL Server, MySQL, PostgreSQL, Oracle, MongoDB)
- **Connection String**: Secure connection string configuration with credential management
- **Connection Pooling**: Optimization of connection pool settings for performance and resource utilization
- **SSL/TLS Configuration**: Secure communication setup for sensitive data transmission

**Performance Optimization:**
- **Batch Processing**: Configuration of optimal batch sizes for database performance
- **Transaction Management**: ACID compliance configuration for data integrity requirements
- **Indexing Strategies**: Guidance on database indexing for optimal write performance
- **Capacity Planning**: Initial capacity planning based on expected data volumes

### File Output Target Creation

File-based targets require storage and format configuration:

**Storage Configuration:**
- **Storage Location**: Local filesystem or network-attached storage configuration
- **Directory Structure**: Organizational structure for file storage and management
- **File Naming**: Naming conventions for files including timestamps and metadata
- **Access Permissions**: File system permissions for security and access control

**Format and Rotation:**
- **Output Format**: Selection of file format (JSON, CSV, XML, custom) based on consumption requirements
- **Rotation Policies**: Time-based, size-based, or custom rotation policies for file management
- **Compression Options**: Compression configuration for storage efficiency
- **Archive Policies**: Long-term archival policies for compliance and storage optimization

### Console Target Creation

Console targets provide specialized debugging and development capabilities:

**Development Configuration:**
- **Output Format**: Selection of output format optimized for console display and debugging
- **Filtering Options**: Configuration of filtering for focused debugging and analysis
- **Performance Display**: Real-time performance metrics display for development optimization
- **Log Level Configuration**: Configurable log levels for different development phases

**Operational Integration:**
- **Development Workflow**: Integration with development and testing workflows
- **Quality Assurance**: Configuration for QA processes and validation procedures
- **Performance Testing**: Setup for performance testing and optimization activities
- **Production Readiness**: Validation steps before production deployment

## Creation Best Practices

### Configuration Management

**Naming Conventions:**
- **Descriptive Names**: Use clear, descriptive names that indicate target purpose and environment
- **Consistent Formatting**: Maintain consistent naming patterns across all target configurations
- **Environment Identification**: Include environment indicators (dev, staging, prod) in target names
- **Version Management**: Consider versioning schemes for target configurations

**Documentation Standards:**
- **Purpose Documentation**: Clearly document the intended purpose and usage of each target
- **Configuration Details**: Maintain comprehensive documentation of configuration choices and rationale
- **Change Management**: Document all configuration changes with timestamps and reasons
- **Contact Information**: Include responsible team or individual contact information

### Security Configuration

**Credential Management:**
- **Secure Storage**: Use secure credential storage mechanisms and avoid hardcoded credentials
- **Credential Rotation**: Implement regular credential rotation policies and procedures
- **Least Privilege**: Configure targets with minimum required permissions for operation
- **Access Auditing**: Enable auditing for all target access and operations

**Network Security:**
- **Encryption**: Enable encryption for all data transmission to targets
- **Network Segmentation**: Use appropriate network segmentation for target access
- **Firewall Configuration**: Configure firewalls to allow only necessary traffic
- **VPN/Private Network**: Use VPNs or private networks for sensitive data transmission

### Performance Optimization

**Throughput Configuration:**
- **Batch Size Optimization**: Configure optimal batch sizes based on target characteristics and performance requirements
- **Connection Management**: Optimize connection parameters for high-throughput scenarios
- **Buffering Strategy**: Implement appropriate buffering strategies for reliability and performance
- **Load Testing**: Conduct thorough load testing before production deployment

**Monitoring and Alerting:**
- **Health Monitoring**: Configure comprehensive health monitoring for all targets
- **Performance Metrics**: Set up monitoring for key performance indicators and thresholds
- **Alert Configuration**: Configure alerts for failures, performance degradation, and capacity issues
- **Trend Analysis**: Implement monitoring for long-term performance trend analysis

Target creation provides the foundation for reliable data delivery to diverse output destinations, ensuring that data flows efficiently and securely from DataStream to your chosen targets while maintaining performance, security, and operational excellence.
