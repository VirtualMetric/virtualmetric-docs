# Creating Pipelines

**DataStream** pipelines are the core data processing units that transform, enrich, and route data from various sources to target destinations. The pipeline system supports hierarchical structures with parent and child pipelines, allowing for modular and scalable data processing architectures.

## Creating a New Pipeline

To create a new pipeline, you'll work with a comprehensive configuration interface that guides you through setting up your data processing workflow.

### General Overview Configuration

Begin by configuring the basic pipeline information in the **General Overview** section:

**Pipeline Name**: Enter a name for your pipeline in the **Name** field. This is a required field and should clearly identify the pipeline's purpose and data source. Choose a descriptive name that will help you and other users understand the pipeline's function at a glance.

**Pipeline Description**: Enter a description for your pipeline in the **Description** field. Although optional, this provides detailed information about the pipeline's functionality, data sources, and processing goals. The description field supports up to 100 characters, and the system provides a character counter to help you stay within the limit.

### Device Information Setup

Configure the source system details in the **Device Info** section:

**Device Type Selection**: Use the **Device type** dropdown to select the appropriate device category. Although optional, this selection helps with template matching and processor selection. The dropdown provides various device type options including:
- Firewall systems
- Network devices  
- Security appliances
- Other infrastructure components

**Device Vendor Selection**: Choose the device manufacturer from the **Device vendor** dropdown. This optional field is useful for pipeline management and helps with template matching. The dropdown includes options for major technology vendors and device manufacturers.

**Target Platform Selection**: Select your destination platform from the **Target** dropdown. This optional field specifies where processed data will be sent after pipeline processing. Available target options include:
- Microsoft Sentinel
- Elasticsearch
- Splunk
- Other SIEM platforms
- Analytics platforms
- Custom endpoints

### Completing Pipeline Creation

After configuring all necessary fields, you have two options:

- Click **Create pipeline** to finalize the pipeline configuration and proceed to the next setup phase
- Click **Cancel** to discard the current configuration and return to the previous screen

### Example Configuration

Here's an example of a completed pipeline configuration:

- **Name**: Test_Pipeline
- **Description**: "This is a test pipeline" (23/100 characters used)
- **Device Type**: Firewall
- **Device Vendor**: Microsoft  
- **Target**: Microsoft Sentinel

This configuration creates a pipeline designed to process firewall data from Microsoft devices and send the processed results to Microsoft Sentinel for security analysis.

---

## Managing Pipeline Hierarchies

### Adding Child Pipelines

Child pipelines allow you to create modular processing units within a parent pipeline structure. This hierarchical approach enables you to break down complex data processing workflows into manageable, specialized components.

To add a child pipeline, access the "Add child pipeline" option through the pipeline management system. This process provides the following options:

**Child Pipeline Name**: Enter a unique identifier for the sub-pipeline in the designated text field. This name should be descriptive and clearly indicate the specific processing function this child pipeline will perform within the parent pipeline structure. Choose names that reflect the data transformation or routing purpose of the child pipeline.

**Add Child Pipeline**: Click this button to confirm the creation of the new child pipeline with the specified name. The system will create the child pipeline and integrate it into the parent pipeline's hierarchy.

**Cancel**: Select this option to discard the child pipeline creation process without making any changes to the existing pipeline structure.

### Example Child Pipeline Creation

Here's an example of creating a child pipeline:

- **Child Pipeline Name**: child_pipeline

When you complete this process, the system creates a subordinate processing unit named "child_pipeline" that can handle specific data transformation tasks while remaining part of the larger pipeline structure. This modular approach allows for better organization, easier maintenance, and more flexible data processing workflows.

## Pipeline Management Interface

The pipeline details interface provides comprehensive management capabilities for monitoring, configuring, and maintaining your data processing pipelines.

### Navigation Structure

The interface includes organized navigation elements to help you move between different pipeline views:

**Breadcrumb Navigation**: The top of the interface displays your current location within the pipeline hierarchy (e.g., "Pipelines / Test_Pipeline"), allowing you to easily navigate back to parent levels or understand your current context.

**Tab Navigation**: Two primary tabs provide different perspectives on your pipeline:
- **General Overview**: Focuses on pipeline metadata, basic configuration, and administrative settings
- **Pipeline Overview**: Concentrates on the technical configuration, processors, and data transformation logic

### Pipeline Hierarchy Display

The left sidebar presents a tree-like view of your complete pipeline structure, making it easy to understand and navigate complex hierarchical configurations:

**Root Pipeline**: The main pipeline container (e.g., "Test_Pipeline") appears at the top level, representing the primary data processing workflow.

**Child Pipelines**: Any subordinate processing units (e.g., "child_pipeline") are displayed as nested items under their parent pipeline, showing the modular structure of your data processing workflow.

**Expansion Options**: An "Add new child pipeline" option remains available in the hierarchy, allowing you to expand your pipeline structure as needed.

### Configuration Editor

The main panel serves as your primary workspace for pipeline configuration:

**YAML Configuration Display**: The pipeline configuration is presented in standard YAML format, providing a structured view of your pipeline's technical specifications.

**Pipeline Description**: Metadata and purpose documentation for the pipeline, helping team members understand the pipeline's role in your data processing architecture.

**Processors Section**: Data transformation components area, which may initially be empty for new pipelines, ready for you to add specific data processing logic and transformation rules.

**Guidance Comments**: Instructional text embedded in the configuration helps guide users through adding processors and configuring data processing workflows.

### Action Controls

The interface provides several control options for managing your pipeline:

**Save Changes**: The "Save changes on selected pipeline" button commits any modifications you've made to the pipeline configuration, ensuring your updates are preserved and applied to the active pipeline.

**Actions Menu**: A dedicated menu provides access to additional pipeline management options and advanced configuration features.

### Advanced Pipeline Management Options

The Actions menu provides several important pipeline management capabilities:

**Add Child Pipeline**: This option allows you to create new subordinate processing units within the current pipeline structure. Use this feature to expand your pipeline's modular architecture and add specialized data processing components.

**Delete Entire Pipeline**: This option removes the complete pipeline and all its components from your DataStream configuration. This is a comprehensive deletion that affects the entire pipeline hierarchy, including all child pipelines and their configurations.

**Safety Measures**: When you select the delete option, the system presents a confirmation step to prevent accidental removal of configured pipelines. This safety mechanism ensures that you intentionally confirm the deletion before the system removes your pipeline configuration and all associated processing logic.

## Pipeline Editing and Configuration

The General Overview tab provides direct editing capabilities for pipeline metadata, allowing you to modify pipeline settings after initial creation.

### General Information Editing

The General Info section contains editable fields for core pipeline metadata:

**Pipeline Name**: An editable text field displays the current pipeline name (such as "Test_Pipeline"). You can modify this name to better reflect the pipeline's purpose or to align with updated naming conventions in your organization.

**Pipeline Description**: A text area allows you to update the pipeline description with real-time character count feedback. The system shows the current description and tracks character usage to help you stay within the maximum limit while providing comprehensive pipeline documentation.

### Device Information Updates

The Device Info section provides dropdown controls for modifying source and destination configuration:

**Device Type**: A dropdown selection allows you to change the source system category. For example, you might update from "Firewall" to another device type as your data sources change or as you repurpose the pipeline for different data processing tasks.

**Device Vendor**: An optional vendor specification field (such as "Microsoft") can be updated to reflect changes in your infrastructure or to improve template matching accuracy.

**Target Platform**: The destination platform selection (such as "Microsoft Sentinel") can be modified to redirect processed data to different analytics platforms, SIEM systems, or custom endpoints as your requirements evolve.

### Edit Controls and Actions

Each editable section includes standard control options:

**Cancel**: This button discards any changes you've made and reverts all fields to their previous values, allowing you to abandon modifications without affecting the pipeline configuration.

**Save**: This button applies all modifications to the pipeline configuration, committing your changes to the active pipeline settings.

This editing interface allows administrators to update pipeline metadata and routing information efficiently without affecting the underlying data processing configuration or disrupting active data flows.

