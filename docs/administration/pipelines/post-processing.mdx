# Post-processing

This is the stage where pipelines attached to destinations perform final transformations before data reaches storage or analysis systems. These transformations ensure that data meets destination-specific requirements and optimizes storage efficiency.

## Key Benefits

The motivation for using post-processing is summarized below by detailing its various aspects.

:::warning
Heavy post-processing can impact delivery latency. Monitor and adjust based on performance requirements.
:::

### Data Routing

Use the `reroute` processor to:

- Direct data to specific targets based on content
- Implement conditional routing logic
- Send data to multiple destinations
- Handle failover scenarios

**Example** - Route based on content:

```yaml
pipeline:
  processors:
    - reroute:
        if: "ctx.severity == 'high'"
        destination: priority_storage
```

### Field Optimization

Optimize fields for storage and queries using:

- **Field Removal**: Use `remove` processor to eliminate unnecessary fields
- **Field Renaming**: Apply `rename` processor for destination-specific field names
- **Field Restructuring**: Use `dot_nester` to flatten or restructure fields
- **Format Conversion**: Convert with `normalize` processor to match destination format

**Example** - Prepare for storage:

```yaml
pipeline:
  processors:
    - remove:
        field: ["temp_field", "debug_info"]
    - rename:
        field: "source_ip"
        target_field: "source.ip"
    - normalize:
        target_format: "ecs"
```

### Microsoft Sentinel Integration

Prepare data for Microsoft Sentinel using:

- **ASIM Normalization**: Convert to ASIM format with `normalize` processor
- **Field Extraction**: Use `grok` or `kv` processors for field parsing
- **Network Processing**: Apply `network_direction` processor for traffic analysis

**Example** - Sentinel preparation:

```yaml
pipeline:
  processors:
    - normalize:
        target_format: "asim"
    - network_direction:
        internal_networks: ["192.168.0.0/16"]
    - grok:
        field: message
        patterns: ["%{SYSLOGTIMESTAMP:TimeGenerated}"]
```

### Timestamp Processing

Handle time-related transformations using:

- **Date Parsing**: Convert timestamps with `date` processor
- **Format Standardization**: Use `date_index_name` for time-based indexing
- **String Processing**: Clean timestamps with `gsub` processor

**Example** - Time processing:

```yaml
pipeline:
  processors:
    - date:
        field: timestamp
        formats: ["dd/MMM/yyyy:HH:mm:ss Z"]
    - date_index_name:
        field: "@timestamp"
        date_rounding: "d"
        index_name_format: "logs-%Y.%m.%d"
```

## Best Practices

### Configuration

1. **Field Management**
   ```yaml
   pipeline:
     processors:
       - dot_nester:
           field: nested_data
           target_field: flat_data
       - remove:
           field: nested_data
   ```

2. **Format Conversion**
   ```yaml
   pipeline:
     processors:
       - normalize:
           target_format: "ecs"
       - rename:
           fields:
             - from: source_host
               to: source.hostname
   ```

### Error Handling

1. **Graceful Failures**
   ```yaml
   pipeline:
     processors:
       - date:
           field: timestamp
           ignore_failure: true
           on_failure:
             - append:
                 field: tags
                 value: date_parse_failed
   ```

2. **Missing Fields**
   ```yaml
   pipeline:
     processors:
       - rename:
           field: optional_field
           target_field: new_name
           ignore_missing: true
   ```

### Performance

1. Monitor processing latency
2. Use error handling for resilience
3. Test with representative data volumes
4. Verify destination compatibility

:::warning
Complex post-processing can impact delivery latency. Monitor performance and adjust as needed.
:::

:::tip
Align post-processing with destination capabilities to maximize performance and minimize storage costs.
:::