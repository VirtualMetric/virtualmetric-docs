---
pagination_prev: null
pagination_next: null
---

# Appendix

## Agent IDs

Predefined **Windows** log channel configurations:

- `491591344758837249` is the base definition id
- `486227243115741541` is for security

There are 3 different security definitons that can be used under the `<vm_root>\package\definitions\module\windows\host\event` directory.

1. `windows_security_log_collector_all`: This is to collect all "Security" related events, "Microsoft-Windows-AppLocker/EXE and DLL", and "Microsoft-Windows-AppLocker/MSI and Script".

2. `windows_security_log_collector_common_example`: This is to collect specific events from "Security", "Microsoft-Windows-AppLocker/EXE and DLL", and "Microsoft-Windows-AppLocker/MSI and Script" channels.

- Security related event ids:

    [`1`, `299`, `300`, `324`, `340`, `403`, `404`, `410`, `411`, `412`, `413`, `431`, `500`, `501`, `1100`, `1102`, `1107`, `1108`, `4608`, `4610`, `4611`, `4614`, `4622`, `4624`, `4625`, `4634`, `4647`, `4648`, `4649`, `4657`, `4661`, `4662`, `4663`, `4665`, `4666`, `4667`, `4670`, `4672`, `4673`, `4674`, `4675`, `4688`, `4689`, `4697`, `4700`, `4702`, `4704`, `4705`, `4716`, `4717`, `4718`, `4719`, `4720`, `4722`, `4723`, `4724`, `4725`, `4726`, `4727`, `4728`, `4729`, `4732`, `4733`, `4735`, `4737`, `4738`, `4739`, `4740`, `4742`, `4744`, `4745`, `4746`, `4750`, `4751`, `4752`, `4754`, `4755`, `4756`, `4757`, `4760`, `4761`, `4762`, `4764`, `4767`, `4768`, `4771`, `4774`, `4778`, `4779`, `4781`, `4793`, `4797`, `4798`, `4799`, `4800`, `4801`, `4802`, `4803`, `4825`, `4826`, `4870`, `4886`, `4887`, `4888`, `4893`, `4898`, `4902`, `4904`, `4905`, `4907`, `4931`, `4932`, `4933`, `4946`, `4948`, `4956`, `4985`, `5024`, `5033`, `5059`, `5136`, `5137`, `5140`, `5145`, `5632`, `6144`, `6145`, `6272`, `6273`, `6278`, `6416`, `6423`, `6424`, `26401`, `30004`]

- Microsoft-Windows-AppLocker/EXE and DLL-related event ids:
  
    [`8001`, `8002`, `8003`, `8004`]

- Microsoft-Windows-AppLocker/MSI and Script-related event ids:

    [`8005`, `8006`, `8007`, `8222`]
 
3. `windows_security_log_collector_minimal_example`

  - Security related event ids:

    [`1102`, `4624`, `4625`, `4657`, `4663`, `4688`, `4700`, `4702`, `4719`, `4720`, `4722`, `4723`, `4724`, `4727`, `4728`, `4732`, `4735`, `4737`, `4739`, `4740`, `4754`, `4755`, `4756`, `4767`, `4799`, `4825`, `4946`, `4948`, `4956`, `5024`, `5033`]

- Microsoft-Windows-AppLocker/EXE and DLL-related event ids:

    [`8001`, `8002`, `8003`, `8004`]

- Microsoft-Windows-AppLocker/MSI and Script-related event ids:

    [`8005`, `8006`, `8007`, `8222`]

## Configuration BNF

All **DataStream** configuration files are in YAML format and conform to the following syntax:

<TermTable>
   <TermCol>`comp-decl`</TermCol>
   <DefCol>`::= <comp-type> ":" "\n\t" <comp-def>`</DefCol>

   <TermCol>`comp-type`</TermCol>
   <DefCol>`::= ("devices"|"targets"|"pipelines"|"routes")`</DefCol>

   <TermCol>`comp-def`</TermCol>
   <DefCol>`::= <id-fld-def> <fld-defs>`</DefCol>

   <TermCol>`id-fld-def`</TermCol>
   <DefCol>`::= "-" <id-fld-name> ":" <id>`</DefCol>

   <TermCol>`id-fld-name`</TermCol>
   <DefCol>`::= "-" <id>`</DefCol>

   <TermCol>`id`</TermCol>
   <DefCol>`::= <txt-val>`</DefCol>

   <TermCol>`fld-defs`</TermCol>
   <DefCol>`::= <fld-def> ["\n" <fld-defs>]*`</DefCol>

   <TermCol>`fld-def`</TermCol>
   <DefCol>`::= <fld-name> ":" <fld-vals>`</DefCol>

   <TermCol>`fld-name`</TermCol>
   <DefCol>`::= <txt-val>`</DefCol>

   <TermCol>`fld-vals`</TermCol>
   <DefCol>`::= (<fld-val>|"[" <fld-val> ["," <fld-vals>]* "]"|["\n\t -" <fld-val>]+)`</DefCol>

   <TermCol>`fld-val`</TermCol>
   <DefCol>`::= (txt-val|num-val)`</DefCol>

   <TermCol>`txt-val`</TermCol>
   <DefCol>`::= <txt-char>+ <alnum-char>*`</DefCol>

   <TermCol>`num-val`</TermCol>
   <DefCol>`::= ('-'|'+')? <num-char>+`</DefCol>

   <TermCol>`alnum-char`</TermCol>
   <DefCol>`::= (<txt-char>|<num-char>)*`</DefCol>

   <TermCol>`txt-char`</TermCol>
   <DefCol>`::= ('a' .. 'z'|'A' .. 'Z'|'_')`</DefCol>

   <TermCol>`num-char`</TermCol>
   <DefCol>`::= '0' .. '9'`</DefCol>
</TermTable>

## File Formats

### Avro

**Apache Avro** is a data serialization system that provides rich data structures and a compact, fast, binary data format. Originally developed within the Apache Hadoop ecosystem, Avro is designed for schema evolution and language-neutral data exchange.

#### üì¶ Binary Layout

|Section|Internal Name|Description|Possible Values / Format|
|--:|:-:|:--|:--|
|**File Header**|`magic`|4-byte magic number identifying Avro files|ASCII: `Obj` followed by `1` byte (hex: `4F 62 6A 01`)|
||`meta`|Metadata map storing key-value pairs (e.g., schema, codec)|Map of string keys to byte values (e.g., `"avro.schema"` ‚Üí JSON schema string)|
||`sync`|16-byte random sync marker used between blocks| 16 random bytes (unique per file)|
|**Data Block**|`blockCount`|Number of records in the block|Long (variable-length zigzag encoding)|
||`blockSize`|Size in bytes of the serialized records (after compression, if any)|Long|
||`blockData`| Serialized records (optionally compressed)|Binary-encoded data per schema|
||`sync`| Sync marker repeated after each block|Same 16-byte value as in header|

#### üß¨ Schema Types (Stored in Metadata)

|Type|Internal Name|Description|Example / Format|
|--:|:-:|:--|:--|
|Primitive|`null`, `boolean`, `int`, `long`, `float`, `double`, `bytes`, `string`|Basic types|`"type": "string"|
|Record|`record`|Named collection of fields|`{ "type": "record", "name": "Person", "fields": [...] }`|
|Enum|`enum`|Named set of symbols| `{ "type": "enum", "name": "Suit", "symbols": ["SPADES", "HEARTS"] }`|
|Array|`array`|Ordered list of items|`{ "type": "array", "items": "string" }`|
|Map|`map`|Key-value pairs with string keys|`{ "type": "map", "values": "int" }`|
|Union|JSON array|Multiple possible types|`[ "null", "string" ]`|
|Fixed|`fixed`|Fixed-size byte array|`{ "type": "fixed", "name": "md5", "size": 16 }`|

#### üß∞ Metadata Keys (in `meta`)

|Key|Description|Example Value|
|--:|:--|:--|
|`avro.schema`|JSON-encoded schema|JSON string defining the schema|
|`avro.codec`|Compression codec used (optional)|`"null"` (default), `"deflate"`, `"snappy"`, `"bzip2"`, `"xz"`|

### Parquet

**Apache Parquet** is a column-oriented binary storage format optimized for analytical workloads. Originally developed within the Apache Hadoop ecosystem, Parquet provides efficient compression and encoding schemes for large-scale data processing.

#### üì¶ Binary Layout

|Section|Internal Name|Description|Possible Values / Format|
|--:|:-:|:--|:--|
|**File Header**|`magic`|4-byte magic number identifying Parquet files|ASCII: `PAR1` (hex: `50 41 52 31`)|
|**Row Group**|`row_group_metadata`|Metadata for each row group|Contains column chunk metadata and statistics|
||`column_chunk`|Data for each column in the row group|Compressed and encoded column data|
|**File Footer**|`metadata`|File-level metadata including schema and row groups|Thrift-encoded metadata structure|
||`metadata_length`|Length of metadata section|4-byte little-endian integer|
||`magic`|Footer magic number|ASCII: `PAR1` (hex: `50 41 52 31`)|

#### üóÇÔ∏è Column Storage Example

**Row-based storage** (traditional):

```plaintext
id,name,last_name,age
1,John,Buck,35
2,Jane,Doe,27
3,Joe,Dane,42
```

**Column-based Storage** (Parquet):

```plaintext
id: [1, 2, 3]
name: [John, Jane, Joe]
last_name: [Buck, Doe, Dane]
age: [35, 27, 42]
```

#### üîß Encoding Types

|Encoding|Internal Name|Description|Use Case|
|--:|:-:|:--|:--|
|Plain|`PLAIN`|No encoding applied|Small datasets or unsorted data|
|Dictionary|`PLAIN_DICTIONARY`|Values replaced with dictionary indices|Repeated string values|
|Run Length|`RLE`|Consecutive identical values compressed|Sparse or repetitive data|
|Bit Packing|`BIT_PACKED`|Pack values using minimum required bits|Boolean or small integer ranges|
|Delta|`DELTA_BINARY_PACKED`|Store differences between consecutive values|Sorted numerical data|

#### üóúÔ∏è Compression Codecs

|Codec|Description|Best For|
|--:|:--|:--|
|`UNCOMPRESSED`|No compression applied|Testing or very small files|
|`SNAPPY`|Fast compression/decompression|General-purpose, balanced performance|
|`GZIP`|Higher compression ratio|Storage-constrained environments|
|`LZO`|Fast decompression|Read-heavy workloads|
|`BROTLI`|Modern compression algorithm|High compression ratio needs|
|`LZ4`|Extremely fast compression|Low-latency applications|

### PEM

**Privacy Enhanced Mail (PEM)** is a Base64-encoded format for storing cryptographic keys, certificates, and other security-related data. Despite its name, PEM is widely used beyond email applications for various cryptographic purposes.

#### üì¶ Structure Format

|Component|Description|Example|
|--:|:--|:--|
|**Begin Marker**|Header identifying content type|`-----BEGIN CERTIFICATE-----`|
|**Headers**|Optional key-value metadata pairs|`Proc-Type: 4,ENCRYPTED`|
|**Encoded Data**|Base64-encoded binary content|`MIIHzTCCBbWgAwIBAgIQaBYE3/M08XHYCnNVmcFBcjANBgkqhkiG9w0BAQsFADBy...`|
|**End Marker**|Footer matching the begin marker|`-----END CERTIFICATE-----`|

#### üîë Common PEM Types

|Type|Begin/End Label|Description|Use Case|
|--:|:-:|:--|:--|
|Certificate|`CERTIFICATE`|X.509 public key certificate|SSL/TLS, code signing|
|Private Key|`PRIVATE KEY`|PKCS#8 private key|General-purpose private key storage|
|RSA Private Key|`RSA PRIVATE KEY`|PKCS#1 RSA private key|RSA-specific private keys|
|Public Key|`PUBLIC KEY`|X.509 SubjectPublicKeyInfo|Public key distribution|
|Certificate Request|`CERTIFICATE REQUEST`|PKCS#10 certificate signing request|Certificate authority requests|
|DH Parameters|`DH PARAMETERS`|Diffie-Hellman parameters|Key exchange configuration|
|EC Private Key|`EC PRIVATE KEY`|Elliptic Curve private key|EC cryptography|

#### üîí Encrypted PEM Format

|Field|Description|Example|
|--:|:--|:--|
|**Proc-Type**|Processing type and encryption flag|`Proc-Type: 4,ENCRYPTED`|
|**DEK-Info**|Encryption algorithm and IV|`DEK-Info: AES-256-CBC,A1B2C3D4E5F6...`|
|**Encrypted Data**|Base64-encoded encrypted content|`Encrypted binary data...`|

#### üìã Example Structure

```encoding
-----BEGIN RSA PRIVATE KEY-----
Proc-Type: 4,ENCRYPTED
DEK-Info: AES-256-CBC,A1B2C3D4E5F67890A1B2C3D4E5F67890

MIIEpAIBAAKCAQEA2Z3QX0KZVE9I+sLlmEUKkYgJiEQSvfNF6JUVNBQdHPvs
kNkRFWGLQQEjLXPOCjGhvQZZLvbPjVZGKlnTJ1yJQvzjhvnP0zJhExFmKWz8
...
-----END RSA PRIVATE KEY-----
```

PEM files are text-based, human-readable, and can contain multiple objects separated by blank lines. They're commonly used in web servers, email systems, and various security applications.

## Log Formats

### ASIM

The Advanced Security Information Model is a layer between the data and the user to configure what and how to ingest data from a source and to route it to a destination. ASIM provides standardization for security-focused log data.

Available ASIM tables:

- `ASimAuditEventLogs`
- `ASimAuthenticationEventLogs` 
- `ASimDhcpEventLogs`
- `ASimDnsActivityLogs`
- `ASimFileEventLogs`
- `ASimNetworkSessionLogs`
- `ASimProcessEventLogs`
- `ASimRegistryEventLogs`
- `ASimUserManagementActivityLogs`
- `ASimWebSessionLogs`

### CEF

The Common Event Format is a standardized security event logging layout. Its creator is ArcSight, and it has been widely adopted by the industry. Features include:

- Standard header with 7 required fields
- Extensible key-value pair extension format
- Header fields include: version, device vendor, device product, device version, signature ID, name, and severity
- Extension fields use a key=value format

### CIM

The Common Information Model (CIM) is a standardized data model developed by Splunk. It provides:

**Common Fields**:

|Field Category|Fields|Description|
|:-:|:--|:--|
|Base Fields|`source`, `sourcetype`, `timestamp`, `host`, `index`|Core fields for event identification and source tracking|
|Identity Fields|`user`, `src_user`, `dest_user`|User identification and authentication tracking|
|Network Fields|`src_ip`, `dest_ip`, `src_port`, `dest_port`|Network communication endpoints|

**Data Models**:

|Model Type|Fields|Purpose|
|:-:|:--|:--|
|Authentication|`action`, `app`, `status`, `auth_method`|Track authentication events and access control|
|Network Traffic|`bytes`, `protocol`, `direction`, `tcp_flags`|Monitor network communications and traffic patterns|
|Vulnerability|`severity`, `signature`, `vulnerability_id`|Track security vulnerabilities and risks|
|Changes|-|Track system and configuration changes|
|Intrusion Detection|-|Monitor security threats and intrusions|

**Event Categories**:

|Category|Event Types|Description|
|--:|:--|:--|
|Authentication|`success`, `failure`, `logout`|Authentication-related events and outcomes|
|Network|`connection`, `alert`, `traffic`|Network activity and communications|
|System|`change`, `status`, `error`|System-level events and status changes|
|Security|-|Security-related events and alerts|

### ECS

Elastic Common Schema (ECS) is a specification that defines a common set of fields for ingesting data into Elasticsearch. Field groups include:

|Field Group|Core Fields|Description|
|:-:|:--|:--|
|Base Fields|`@timestamp`, `tags`, `labels`, `message`|Universal fields that appear in every event|
|Host|`host.name`, `host.ip`, `host.os.*`, `host.mac`|Information about the host machine|
|Network|`network.protocol`, `network.type`, `network.direction`, `network.bytes`|Network activity details|
|Source/Destination|`source.ip`, `source.port`, `dest.ip`, `dest.port`|Communication endpoint information|
|User|`user.id`, `user.name`, `user.domain`, `user.email`|User-related information|
|Event|`event.category`, `event.type`, `event.action`, `event.outcome`|Event classification details|
|File|`file.path`, `file.size`, `file.type`, `file.hash.*`|File-related information|
|Process|`process.pid`, `process.name`, `process.args`, `process.parent.*`|Process execution details|
|Error|`error.code`, `error.message`, `error.type`, `error.stack_trace`|Error-related information|
|Trace|`trace.id`, `span.id`, `transaction.id`|Distributed tracing data|

### eStreamer

Cisco's event streaming protocol used by Firepower Management Center (FMC) to send events to export security event data, intrusion alerts, connection logs, and other network telemetry in real-time. It enables integration with external SIEMs and analytics platforms, providing deep visibility into network security events.

|Field|Description|
|--:|:--|
|`eventType`|Type of event (e.g., intrusion, connection, malware)|
|`timestamp`|Time the event occurred|
|`sourceIP`|Source IP address|
|`destinationIP`|Destination IP address|
|`sourcePort`|Source port number|
|`destinationPort`|Destination port number|
|`protocol`|Transport protocol (TCP, UDP, etc.)|
|`userIdentity`|Associated user (if available)|
|`deviceUUID`|Unique identifier for the source device|
|`application`|Detected application (e.g., HTTP, SSH)|
|`threatScore`|Severity or risk rating of the event|
|`signatureID`|Identifier for the security rule triggered|
|`signatureName`|Description of the triggered security rule|
|`malwareSHA256`|Hash of detected malware (if applicable)|
|`fileName`|Name of the file involved in the event|

eStreamer provides detailed security telemetry and integrates with SIEMs for real-time threat monitoring and forensic analysis.

### IPFIX

The IP Flow Information Export is an IETF-standardized protocol for exporting flow-based traffic data from routers, switches, and other network devices. It is an evolution of NetFlow, offering greater flexibility by supporting custom fields and templates for diverse network monitoring, security, and analytics applications. IPFIX allows vendors to define and export additional data types beyond traditional NetFlow fields.

|Field|Description|
|--:|:--|
|`sourceIPv4Address`|Source IP address (IPv4)|
|`destinationIPv4Address`|Destination IP address (IPv4)|
|`sourceIPv6Address`|Source IP address (IPv6)|
|`destinationIPv6Address`|Destination IP address (IPv6)|
|`sourceTransportPort`|Source port number|
|`destinationTransportPort`|Destination port number|
|`protocolIdentifier`|Transport protocol (TCP, UDP, etc.)|
|`packetTotalCount`|Number of packets in the flow|
|`octetTotalCount`|Total bytes transferred|
|`flowStartMilliseconds`|Start timestamp in milliseconds|
|`flowEndMilliseconds`|End timestamp in milliseconds|
|`tcpControlBits`|TCP control tcp_flags|
|`ipClassOfService`|Type of Service (QoS marking)|
|`bgpSourceAsNumber`|Source BGP Autonomous System (AS) number|
|`bgpDestinationAsNumber`|Destination BGP AS number|
|`flowEndReason`|Reason the flow ended (e.g. timeout, TCP FIN)|

IPFIX extends NetFlow by supporting variable-length fields and user-defined templates, making it highly adaptable for modern network monitoring needs.

### LEEF

The Log Event Extended Format is an enterprise security event logging format created by IBM QRadar. 

Features:

- Lightweight parsing requirements
- Fixed header fields: version, vendor, product, version, eventID
- Variable attributes section
- Optimized for SIEM processing

### NetFlow

A network protocol developed by Cisco for collecting, analyzing, and monitoring network traffic. It captures metadata about IP traffic flows, providing insights into bandwidth usage, security threats, and network performance. NetFlow records include key details such as source and destination IPs, ports, protocol types, and timestamps.

|Field|Description|
|--:|:--|
|`SrcAddr`|Source IP address|
|`DstAddr`|Destination IP address|
|`SrcPort`|Source port number|
|`DstPort`|Destination port number|
|`Protocol`|Transport protocol (TCP, UDP, etc.)|
|`Packets`|Number of packets in the flow|
|`Bytes`|Total bytes transferred|
|`StartTime`|Timestamp of the first packet in the flow|
|`EndTime`|Timestamp of the last packet in the flow|
|`SrcAS`|Source Autonomous System (AS) number|
|`DstAS`|Destination Autonomous System (AS) number|
|`TCPFlags`|TCP control flags for the flow|
|`ToS`|Type of Service (QoS marking)|
|`NextHop`|IP address of the next hop router|
|`FlowDuration`|Duration of the flow in milliseconds|

This is a general overview; actual fields may vary depending on the versions and implementations.

### sFlow

sFlow (Sampled Flow) is a network monitoring protocol designed for high-speed networks. Unlike NetFlow and IPFIX, which capture complete flow records, sFlow uses packet sampling to provide scalable and efficient traffic analysis. It operates by embedding monitoring agents in network devices that randomly sample packets and send them to a central collector for analysis.  

|Field|Description|
|--:|:--|
|`sampleSequenceNumber`|Unique identifier for the sampled packet|
|`sourceIP`|Source IP address|
|`destinationIP`|Destination IP address|
|`sourcePort`|Source port number|
|`destinationPort`|Destination port number|
|`protocol`|Transport protocol (TCP, UDP, etc.)|
|`sampledPacketSize`|Size of the sampled packet in bytes|
|`inputInterface`|Interface where the packet was received|
|`outputInterface`|Interface where the packet was forwarded|
|`vlanID`|VLAN identifier of the packet|
|`tcpFlags`|TCP control flags|
|`flowSampleType`|Type of sampling (e.g., packet, counter)|
|`samplingRate`|Ratio of sampled packets to total packets|
|`agentAddress`|IP address of the device performing sampling|
|`collectorAddress`|IP address of the sFlow collector|

sFlow's lightweight sampling approach makes it ideal for real-time traffic monitoring in large-scale, high-speed networks.

## Pattern Matching Formats

### Grok Patterns

Common patterns used in log processing:

|Category|Patterns|
|--:|:--|
|General|`DATA` `GREEDYDATA` `NOTSPACE` `SPACE` `WORD`|
|Numeric|`BASE10NUM` `INT` `NUMBER`|
|Networking|`HOSTNAME` `IP` `IPV4` `IPV6` `MAC`|
|Data and Time|`DATESTAMP` `DATESTAMP_RFC822` `TIMESTAMP_ISO8601`|
|File System|`FILENAME` `PATH`|
|HTTP|`HTTPDATE` `HTTPDERRORLOG` `HTTPDUSER`|
|System|`SYSLOGBASE` `SYSLOGHOST` `SYSLOGTIMESTAMP`|
|Other|`EMAILADDRESS` `URIPARAM` `URIPATH` `UUID`|

### Metadata Tags

Common metadata fields used in log processing:

|Field|Subfields|
|--:|:--|
|`_ingest`|`on_failure_processor_tag` `on_failure_processor_type`|
|`_temp`|`observer.mac`|
|`destination`|`bytes` `domain` `ip` `nat.port` `port` `user.domain` `name`|
|`email`|`from.address` `to.address`|
|`event`|`category` `kind` `original` `outcome` `type`|
|`source`|`bytes` `ip` `user.domain` `group.name` `id` `xlatesrc`|
|`observer`|`product` `type` `vendor`|
|`related`|`hash` `ip`|

## Protocols

### Syslog

Standard protocol for system logging:

#### Message Format

**RFC 3164**:

|Field| Description|Example Value|
|--:|:--|:--|
|`PRI`|Priority value = Facility * 8 + Severity, enclosed in angle brackets|`<34>`|
|`TIMESTAMP`|Date and time in "Mmm dd hh:mm:ss" format|Oct 22 12:34:56|
|`HOSTNAME`|Hostname or IP address of the sender|`<hostname>`|
|`TAG`|Application name and optional `PID`| `appname[1234]`|
|`MESSAGE`|Free-form message content|`This is a log message.`|

**RFC 5424**:

|Field|Description|Example Value|
|--:|:--|:--|
|`PRI`|Priority value = Facility * 8 + Severity, enclosed in angle brackets|`<34>`|
|`VERSION`|Syslog protocol version (always 1 for RFC 5424)|`1`|
|`TIMESTAMP`|ISO 8601 timestamp with optional timezone|`2025-01-03T14:07:15.003Z`|
|`HOSTNAME`|FQDN or IP address of the sender|`host.example.com`|
|`APP-NAME`|Application name|`appname`|
|`PROCID`|Process ID|`1234`|
|`MSGID`|Identifier for the type of message|`ID47`|
|`STRUCTURED-DATA`|Optional structured key-value pairs|`[exampleSDID@32473 iut="3"]`|
|`MESSAGE`|Free-form message content|This is a structured log message.|

#### Facility Values

|Code|Facility|
|:-:|:--|
|`0`|kernel messages|
|`1`|user-level messages|
|`2`|mail system|
|...|...|
|`16`‚Äì`23`|`local0` to `local7`|

#### Severity Levels

|Code|Level|
|:-:|:--|
|`0`|Emergency|
|`1`|Alert|
|`2`|Critical|
|`3`|Error|
|`4`|Warning|
|`5`|Notice|
|`6`|Informational|
|`7`|Debug|

### Kafka

#### üì¶ Binary Layout

|Field|Internal Name|Description|Type / Format|Example / Values|
|--:|:--:|:--|:--|:--|
|**Size**|`length`|Total size of the request (excluding this field)|`int32`|e.g. `0x0000012C`|
|**API Key**|`api_key`|Identifies the type of request|`int16`|`0` = Produce, `1` = Fetch, etc.|
|**API Version**|`api_version`|Version of the API being used|`int16`| e.g. `7`|
|**Correlation ID**|`correlation_id`|Used to match requests to responses|`int32`|e.g. `12345`|
|**Client ID**|`client_id`|Optional identifier of the client|`string` (nullable)|e.g. `"my-client"`|
|**Request Body**|*(varies by API)*|The actual request payload|Structured binary|Depends on `api_key` and `api_version`|

#### üîë Common API Keys

|API Key|Name|Purpose|
|--:|:--|:--|
|`0`|Produce|Send messages to a topic|
|`1`|Fetch|Retrieve messages from a topic|
|`3`|Metadata|Get topic/partition info|
|`8`|Offset|Get earliest/latest offsets|
|`18`|ApiVersions|Discover supported API versions|
|`21`|SaslHandshake|SASL authentication handshake|
|`22`|SaslAuthenticate|SASL authentication|
|`42`|DescribeCluster|Get cluster metadata|

#### üß± Primitive Types Used

|Type|Description|
|:-:|---|
|`int8/16/32/64`|Signed integers (big-endian)|
|`string`|Length-prefixed UTF-8 string|
|`array<T>`|Length-prefixed array of type `T`|
|`bytes`|Length-prefixed byte array|
|`varint`|Variable-length integer (zigzag encoding)|

#### üîÑ Response Structure

|Field|Description|
|--:|:--|
|`correlation_id`|Matches the request|
|`response_body`|Depends on the request type|

### Redis

Redis Serialization Protocol (RESP) for client-server communication:

#### Message Format

|Field|Description|Example Value|
|--:|:--|:--|
|**Type**|First byte indicates data type|`+` (Simple String), `-` (Error), `:` (Integer), `$` (Bulk String), `*` (Array)|
|**Data**|Payload following type indicator|`OK\r\n`, `3\r\n`, `$5\r\nhello\r\n`|
|**Terminator**|CRLF sequence marking end of element|`\r\n`|

#### Data Types

|Type|Indicator|Format|Example|
|:-:|:-:|:--|:--|
|Simple String|`+`|`+<string>\r\n`|`+OK\r\n`|
|Error|`-`|`-<error>\r\n`|`-ERR unknown command\r\n`|
|Integer|`:`|`:<number>\r\n`|`:1000\r\n`|
|Bulk String|`$`|`$<length>\r\n<string>\r\n`|`$5\r\nhello\r\n`|
|Array|`*`|`*<count>\r\n<elements>`|`*2\r\n$3\r\nfoo\r\n$3\r\nbar\r\n`|

### RabbitMQ

Advanced Message Queuing Protocol (AMQP) 0-9-1 frame structure:

#### üì¶ Binary Layout

|Field|Internal Name|Description|Type / Format|Example / Values|
|--:|:--:|:--|:--|:--|
|**Type**|`frame_type`|Type of frame|`uint8`|`1` = Method, `2` = Header, `3` = Body, `8` = Heartbeat|
|**Channel**|`channel_id`|Channel number|`uint16`|e.g. `1`, `0` for connection-level|
|**Size**|`frame_size`|Payload size in bytes|`uint32`|e.g. `0x00000014`|
|**Payload**|`payload`|Frame-specific data|Binary|Depends on `frame_type`|
|**End**|`frame_end`|Frame terminator|`uint8`|Always `0xCE`|

#### üîë Frame Types

|Type|Name|Purpose|
|--:|:--|:--|
|`1`|Method|AMQP method calls (open, close, publish, etc.)|
|`2`|Header|Content header with properties|
|`3`|Body|Message content data|
|`8`|Heartbeat|Keep-alive signal|

### NATS

NATS protocol for lightweight messaging:

#### Message Format

|Field|Description|Example Value|
|--:|:--|:--|
|**Operation**|Command type|`PUB`, `SUB`, `MSG`, `PING`, `PONG`, `INFO`, `CONNECT`|
|**Subject**|Message topic/subject|`foo.bar`, `user.123`|
|**Reply-To**|Optional reply subject|`_INBOX.abc123`|
|**Payload Size**|Byte length of payload|`13`|
|**Payload**|Message data|`Hello, World!`|
|**Terminator**|CRLF sequence|`\r\n`|

#### Protocol Operations

|Operation|Format|Purpose|
|:-:|:--|:--|
|`PUB`|`PUB <subject> [reply-to] <size>\r\n<payload>\r\n`|Publish message|
|`SUB`|`SUB <subject> [queue] <sid>\r\n`|Subscribe to subject|
|`MSG`|`MSG <subject> <sid> [reply-to] <size>\r\n<payload>\r\n`|Received message|
|`PING`|`PING\r\n`|Keep-alive request|
|`PONG`|`PONG\r\n`|Keep-alive response|

### SMTP

Simple Mail Transfer Protocol for email transmission:

#### Message Format

|Field|Description|Example Value|
|--:|:--|:--|
|**Command**|SMTP command|`MAIL`, `RCPT`, `DATA`, `HELO`, `EHLO`, `QUIT`|
|**Parameters**|Command arguments|`FROM:<sender@domain.com>`, `TO:<recipient@domain.com>`|
|**Response Code**|3-digit status code|`250`, `354`, `550`|
|**Response Text**|Human-readable message|`OK`, `Start mail input`, `Mailbox unavailable`|
|**Terminator**|CRLF sequence|`\r\n`|

#### Response Codes

|Code|Category|Description|
|:-:|:-:|:--|
|`2xx`|Success|Command completed successfully|
|`3xx`|Intermediate|Command accepted, more info needed|
|`4xx`|Transient Error|Temporary failure, retry possible|
|`5xx`|Permanent Error|Command failed, do not retry|

### TFTP

Trivial File Transfer Protocol for simple file transfers:

#### üì¶ Binary Layout

|Field|Internal Name|Description|Type / Format|Example / Values|
|--:|:--:|:--|:--|:--|
|**Opcode**|`opcode`|Operation type|`uint16`|`1` = RRQ, `2` = WRQ, `3` = DATA, `4` = ACK, `5` = ERROR|
|**Filename**|`filename`|File path (RRQ/WRQ only)|Null-terminated string|`config.txt\0`|
|**Mode**|`mode`|Transfer mode (RRQ/WRQ only)|Null-terminated string|`octet\0`, `netascii\0`|
|**Block Number**|`block_num`|Data block sequence (DATA/ACK)|`uint16`|e.g. `1`, `2`, `3`|
|**Data**|`data`|File content (DATA only)|Binary|Up to 512 bytes|
|**Error Code**|`error_code`|Error type (ERROR only)|`uint16`|`0` = Not defined, `1` = File not found|
|**Error Message**|`error_msg`|Error description (ERROR only)|Null-terminated string|`File not found\0`|

#### üîë Opcodes

|Opcode|Name|Purpose|
|--:|:--|:--|
|`1`|RRQ|Read Request|
|`2`|WRQ|Write Request|
|`3`|DATA|Data packet|
|`4`|ACK|Acknowledgment|
|`5`|ERROR|Error packet|