---
pagination_prev: null
pagination_next: null
---

# Appendix

## CLI

The following table lists all available switches and parameters for the **DataStream Director** command-line binary `vmetric-director`:

|Switch|Description|Default Value|Possible Values|
|--:|:--|:--|:--|
|`-address`|**Generator** target address|`127.0.0.1:514`|IP:port|
|`-agentless`|Run without service installation|`false`|`true`, `false`|
|`-autodiscovery`|Enable auto-discovery (sentinel mode)|`false`|`true`, `false`|
|`-background`|Run in background|`false`|`true`, `false`|
|`-clear`|Clear statistics (stats mode)|`false`|`true`, `false`|
|`-compare-version`|Compare version with current||Version string|
|`-config`|Path to configuration file||File path|
|`-console`|Run in _console_ mode|`false`|`true`, `false`|
|`-count`|**Generator** message count|`1000`|Integer|
|`-debug-level`|Debug level (console mode)||Integer|
|`-definition-id`|Pipeline definition ID||String|
|`-diff`|Show diff in pipeline output|`false`|`true`, `false`|
|`-director`|Run in **Director** mode|`true`|`true`, `false`|
|`-duration`|**Generator** duration in seconds|`300`|Integer|
|`-example`|Show example configuration|`false`|`true`, `false`|
|`-expected`|Pipeline expected output path||File path|
|`-export-json`|Export pipeline as JSON|`false`|`true`, `false`|
|`-extended`|Extended pipeline output|`false`|`true`, `false`|
|`-file-path`|**Generator** input file path||File path|
|`-filter`|Filter log output (console mode)||String|
|`-generator`|Run in **Generator** mode|`false`|`true`, `false`|
|`-info`|Show service information|`false`|`true`, `false`|
|`-input`|Pipeline input path||File path|
|`-interval`|**Generator** interval in seconds|`1`|Integer|
|`-message`|**Generator** message|`VirtualMetric Test Message`|String|
|`-mode`|Specifies the operation mode|`director`|`director`, `supervisor`, `update`, `console`, `pipeline`, `sentinel`, `snmpwalk`, `generator`, `stats`|
|`-name`|Pipeline name||String|
|`-now`|Generate message immediately|`false`|`true`, `false`|
|`-output`|Pipeline output path||File path|
|`-path`|Installation path||Directory path|
|`-pfx2pem`|Convert _PFX_ certificate to PEM format||File path|
|`-pipeline`|Run in _pipeline_ mode|`false`|`true`, `false`|
|`-protocol`|**Generator** protocol|`syslog`|`syslog`, `tcp`, `http`, `netflow`, `vmf`|
|`-sentinel`|Run in _Sentinel_ mode|`false`|`true`, `false`|
|`-service`|Service control operation||`install`, `uninstall`, `start`, `stop`, `restart`|
|`-service-name`|Custom service name||String|
|`-severity`|**Generator** message severity|`Error`|Severity level|
|`-snmp-community`|_SNMP_ community string||String|
|`-snmp-device-id`|_SNMP_ device ID||String|
|`-snmp-host`|_SNMP_ host address||IP/hostname|
|`-snmp-oid`|_SNMP_ OID|`.1.3`|OID string|
|`-snmp-port`|_SNMP_ port|`161`|Port number|
|`-snmp-version`|_SNMP_ version|`2c`|`1`, `2c`, `3`|
|`-snmpwalk`|Run in _SNMPWalk_ mode|`false`|`true`, `false`|
|`-stats`|Show statistics|`false`|`true`, `false`|
|`-stop`|Stop running process|`false`|`true`, `false`|
|`-supervisor`|Run in _supervisor_ mode|`false`|`true`, `false`|
|`-update`|Run in _update_ mode|`false`|`true`, `false`|
|`-validate`|Validate configuration|`false`|`true`, `false`|
|`-version`|Display _version_ information|`false`|`true`, `false`|
|`-visualize`|Visualize pipeline|`false`|`true`, `false`|
|`-vpc`|Show _product code_|`false`|`true`, `false`|

### Common Command Combinations

The following are the valid switch combinations for the indicated tasks:

#### General Tasks

- Display _version_ information:

  ```
  vmetric-director -version
  ```

- Show _example_ configuration:

  ```
  vmetric-director -example
  ```

- Run configuration tool:

  ```
  vmetric-director -config [config_file_path]
  ```

- Compare _version_:

  ```
  vmetric-director -compare-version [version_string]
  ```

- Convert _PFX_ certificate to _PEM_:

  ```
  vmetric-director -pfx2pem [certificate_path]
  ```

- Validate configuration:

  ```
  vmetric-director -validate
  ```
  
  -or-

  ```
  vmetric-director -mode validate
  ```

#### Service Management

- Install service:

  ```
  vmetric-director -service install [-service-name custom_name] [-path installation_path]
  ```

- Uninstall service:

  ```
  vmetric-director -service uninstall [-service-name custom_name]
  ```

- Start service:

  ```
  vmetric-director -service start [-service-name custom_name]
  ```

- Stop service:

  ```
  vmetric-director -service stop [-service-name custom_name]
  ```

- Restart service:

  ```
  vmetric-director -service restart [-service-name custom_name]
  ```

- Run in background (without service):

  ```
  vmetric-director -background [-mode director|supervisor]
  ```

- Run in _agentless_ mode:

  ```
  vmetric-director -agentless [-mode director|supervisor]
  ```

- Show service information:

  ```
  vmetric-director -info [-mode director|supervisor]
  ```

- Show _product code_:

  ```
  vmetric-director -vpc [-mode director|supervisor]
  ```

- Stop running process:

  ```
  vmetric-director -stop [-mode director|supervisor]
  ```

#### Operational Modes

- Console mode:

  ```
  vmetric-director -mode console [-filter filter_string] [-debug-level level]
  ```

  -or-

  ```
  vmetric-director -console [-filter filter_string] [-debug-level level]
  ```

- Pipeline mode:

  ```
  vmetric-director -mode pipeline -name [pipeline_name] [-path path] [-definition-id id] [-input input_file] [-output output_file] [-expected expected_file] [-filter filter] [-diff] [-validate] [-visualize] [-extended] [-export-json]
  ```

  -or-

  ```
  vmetric-director -pipeline -name [pipeline_name] [-path path] [-definition-id id] [-input input_file] [-output output_file] [-expected expected_file] [-filter filter] [-diff] [-validate] [-visualize] [-extended] [-export-json]
  ```

- Generator mode:
  ```
  vmetric-director -mode generator [-protocol syslog|tcp|http|netflow|vmf] [-address target_address] [-severity level] [-message message_text] [-count message_count] [-interval seconds] [-duration seconds] [-now] [-file-path file_path]
  ```

  -or-

  ```
  vmetric-director -generator [-protocol syslog|tcp|http|netflow|vmf] [-address target_address] [-severity level] [-message message_text] [-count message_count] [-interval seconds] [-duration seconds] [-now] [-file-path file_path]
  ```

- Sentinel mode:

  ```
  vmetric-director -mode sentinel [-autodiscovery]
  ```

  -or-

  ```
  vmetric-director -sentinel [-autodiscovery]
  ```

- SNMPWalk mode:

  ```
  vmetric-director -mode snmpwalk -snmp-device-id [device_id] -snmp-host [host] [-snmp-port port] [-snmp-version 1|2c|3] [-snmp-community community_string] [-snmp-oid oid]
  ```

  -or-

  ```
  vmetric-director -snmpwalk -snmp-device-id [device_id] -snmp-host [host] [-snmp-port port] [-snmp-version 1|2c|3] [-snmp-community community_string] [-snmp-oid oid]
  ```

- Update mode:

  ```
  vmetric-director -mode update
  ```

  -or-
  
  ```
  vmetric-director -update
  ```

- Supervisor mode:

  ```
  vmetric-director -mode supervisor
  ```

  -or-

  ```
  vmetric-director -supervisor
  ```

- Statistics mode:

  ```
  vmetric-director -mode stats [-clear]
  ```

  -or-

  ```
  vmetric-director -stats [-clear]
  ```

- **Director** mode (default):

  ```
  vmetric-director
  ```

  -or-

  ```
  vmetric-director -mode director
  ```
  
  -or-

  ```
  vmetric-director -director
  ```

### Protocol-Specific Generator Tasks

The following can be used to simulate various log streaming protocols:

- _Syslog_ generator:

  ```
  vmetric-director -mode generator -protocol syslog -address 127.0.0.1:514 -severity Error -message "Test Message" -count 1000 -interval 1 -duration 300
  ```

- _TCP_ generator:

  ```
  vmetric-director -mode generator -protocol tcp -address 127.0.0.1:9000 -message "Test Message" -count 1000 -interval 1 -duration 300
  ```

- _HTTP_ generator:

  ```
  vmetric-director -mode generator -protocol http -address http://127.0.0.1:8080/logs -message "Test Message" -count 1000 -interval 1 -duration 300
  ```

- _Netflow_ generator:

  ```
  vmetric-director -mode generator -protocol netflow -address 127.0.0.1:2055 -count 1000 -interval 1 -duration 300
  ```

- _VMF_ generator:

  ```
  vmetric-director -mode generator -protocol vmf -file-path input.json -message "Test Message" -count 1000 -interval 1 -duration 300
  ```

## Configuration BNF

All **DataStream** configuration files are in YAML format and conform to the following syntax:

<TermTable>
   <TermCol>`comp-decl`</TermCol>
   <DefCol>`::= <comp-type> ":" "\n\t" <comp-def>`</DefCol>

   <TermCol>`comp-type`</TermCol>
   <DefCol>`::= ("devices"|"targets"|"pipelines"|"routes")`</DefCol>

   <TermCol>`comp-def`</TermCol>
   <DefCol>`::= <id-fld-def> <fld-defs>`</DefCol>

   <TermCol>`id-fld-def`</TermCol>
   <DefCol>`::= "-" <id-fld-name> ":" <id>`</DefCol>

   <TermCol>`id-fld-name`</TermCol>
   <DefCol>`::= "-" <id>`</DefCol>

   <TermCol>`id`</TermCol>
   <DefCol>`::= <txt-val>`</DefCol>

   <TermCol>`fld-defs`</TermCol>
   <DefCol>`::= <fld-def> ["\n" <fld-defs>]*`</DefCol>

   <TermCol>`fld-def`</TermCol>
   <DefCol>`::= <fld-name> ":" <fld-vals>`</DefCol>

   <TermCol>`fld-name`</TermCol>
   <DefCol>`::= <txt-val>`</DefCol>

   <TermCol>`fld-vals`</TermCol>
   <DefCol>`::= (<fld-val>|"[" <fld-val> ["," <fld-vals>]* "]"|["\n\t -" <fld-val>]+)`</DefCol>

   <TermCol>`fld-val`</TermCol>
   <DefCol>`::= (txt-val|num-val)`</DefCol>

   <TermCol>`txt-val`</TermCol>
   <DefCol>`::= <txt-char>+ <alnum-char>*`</DefCol>

   <TermCol>`num-val`</TermCol>
   <DefCol>`::= ('-'|'+')? <num-char>+`</DefCol>

   <TermCol>`alnum-char`</TermCol>
   <DefCol>`::= (<txt-char>|<num-char>)*`</DefCol>

   <TermCol>`txt-char`</TermCol>
   <DefCol>`::= ('a' .. 'z'|'A' .. 'Z'|'_')`</DefCol>

   <TermCol>`num-char`</TermCol>
   <DefCol>`::= '0' .. '9'`</DefCol>
</TermTable>

## Log Format Standards

### ASIM

The Advanced Security Information Model is a layer between the data and the user to configure what and how to ingest data from a source and to route it to a destination. ASIM provides standardization for security-focused log data.

Available ASIM tables:

- `ASimAuditEventLogs`
- `ASimAuthenticationEventLogs` 
- `ASimDhcpEventLogs`
- `ASimDnsActivityLogs`
- `ASimFileEventLogs`
- `ASimNetworkSessionLogs`
- `ASimProcessEventLogs`
- `ASimRegistryEventLogs`
- `ASimUserManagementActivityLogs`
- `ASimWebSessionLogs`

### CEF

The Common Event Format is a standardized security event logging layout. Its creator is ArcSight, and it has been widely adopted by the industry. Features include:

- Standard header with 7 required fields
- Extensible key-value pair extension format
- Header fields include: version, device vendor, device product, device version, signature ID, name, and severity
- Extension fields use a key=value format

### CIM

The Common Information Model (CIM) is a standardized data model developed by Splunk. It provides:

**Common Fields**:

|Field Category|Fields|Description|
|:-:|:--|:--|
|Base Fields|`source`, `sourcetype`, `timestamp`, `host`, `index`|Core fields for event identification and source tracking|
|Identity Fields|`user`, `src_user`, `dest_user`|User identification and authentication tracking|
|Network Fields|`src_ip`, `dest_ip`, `src_port`, `dest_port`|Network communication endpoints|

**Data Models**:

|Model Type|Fields|Purpose|
|:-:|:--|:--|
|Authentication|`action`, `app`, `status`, `auth_method`|Track authentication events and access control|
|Network Traffic|`bytes`, `protocol`, `direction`, `tcp_flags`|Monitor network communications and traffic patterns|
|Vulnerability|`severity`, `signature`, `vulnerability_id`|Track security vulnerabilities and risks|
|Changes|-|Track system and configuration changes|
|Intrusion Detection|-|Monitor security threats and intrusions|

**Event Categories**:

|Category|Event Types|Description|
|--:|:--|:--|
|Authentication|`success`, `failure`, `logout`|Authentication-related events and outcomes|
|Network|`connection`, `alert`, `traffic`|Network activity and communications|
|System|`change`, `status`, `error`|System-level events and status changes|
|Security|-|Security-related events and alerts|

### ECS

Elastic Common Schema (ECS) is a specification that defines a common set of fields for ingesting data into Elasticsearch. Field groups include:

|Field Group|Core Fields|Description|
|:-:|:--|:--|
|Base Fields|`@timestamp`, `tags`, `labels`, `message`|Universal fields that appear in every event|
|Host|`host.name`, `host.ip`, `host.os.*`, `host.mac`|Information about the host machine|
|Network|`network.protocol`, `network.type`, `network.direction`, `network.bytes`|Network activity details|
|Source/Destination|`source.ip`, `source.port`, `dest.ip`, `dest.port`|Communication endpoint information|
|User|`user.id`, `user.name`, `user.domain`, `user.email`|User-related information|
|Event|`event.category`, `event.type`, `event.action`, `event.outcome`|Event classification details|
|File|`file.path`, `file.size`, `file.type`, `file.hash.*`|File-related information|
|Process|`process.pid`, `process.name`, `process.args`, `process.parent.*`|Process execution details|
|Error|`error.code`, `error.message`, `error.type`, `error.stack_trace`|Error-related information|
|Trace|`trace.id`, `span.id`, `transaction.id`|Distributed tracing data|

### eStreamer

Cisco's event streaming protocol used by Firepower Management Center (FMC) to send events to export security event data, intrusion alerts, connection logs, and other network telemetry in real-time. It enables integration with external SIEMs and analytics platforms, providing deep visibility into network security events.

|Field|Description|
|--:|:--|
|`eventType`|Type of event (e.g., intrusion, connection, malware)|
|`timestamp`|Time the event occurred|
|`sourceIP`|Source IP address|
|`destinationIP`|Destination IP address|
|`sourcePort`|Source port number|
|`destinationPort`|Destination port number|
|`protocol`|Transport protocol (TCP, UDP, etc.)|
|`userIdentity`|Associated user (if available)|
|`deviceUUID`|Unique identifier for the source device|
|`application`|Detected application (e.g., HTTP, SSH)|
|`threatScore`|Severity or risk rating of the event|
|`signatureID`|Identifier for the security rule triggered|
|`signatureName`|Description of the triggered security rule|
|`malwareSHA256`|Hash of detected malware (if applicable)|
|`fileName`|Name of the file involved in the event|

eStreamer provides detailed security telemetry and integrates with SIEMs for real-time threat monitoring and forensic analysis.

### IPFIX

The IP Flow Information Export is an IETF-standardized protocol for exporting flow-based traffic data from routers, switches, and other network devices. It is an evolution of NetFlow, offering greater flexibility by supporting custom fields and templates for diverse network monitoring, security, and analytics applications. IPFIX allows vendors to define and export additional data types beyond traditional NetFlow fields.

|Field|Description|
|--:|:--|
|`sourceIPv4Address`|Source IP address (IPv4)|
|`destinationIPv4Address`|Destination IP address (IPv4)|
|`sourceIPv6Address`|Source IP address (IPv6)|
|`destinationIPv6Address`|Destination IP address (IPv6)|
|`sourceTransportPort`|Source port number|
|`destinationTransportPort`|Destination port number|
|`protocolIdentifier`|Transport protocol (TCP, UDP, etc.)|
|`packetTotalCount`|Number of packets in the flow|
|`octetTotalCount`|Total bytes transferred|
|`flowStartMilliseconds`|Start timestamp in milliseconds|
|`flowEndMilliseconds`|End timestamp in milliseconds|
|`tcpControlBits`|TCP control tcp_flags|
|`ipClassOfService`|Type of Service (QoS marking)|
|`bgpSourceAsNumber`|Source BGP Autonomous System (AS) number|
|`bgpDestinationAsNumber`|Destination BGP AS number|
|`flowEndReason`|Reason the flow ended (e.g. timeout, TCP FIN)|

IPFIX extends NetFlow by supporting variable-length fields and user-defined templates, making it highly adaptable for modern network monitoring needs.

### LEEF

The Log Event Extended Format is an enterprise security event logging format created by IBM QRadar. 

Features:

- Lightweight parsing requirements
- Fixed header fields: version, vendor, product, version, eventID
- Variable attributes section
- Optimized for SIEM processing

### NetFlow

A network protocol developed by Cisco for collecting, analyzing, and monitoring network traffic. It captures metadata about IP traffic flows, providing insights into bandwidth usage, security threats, and network performance. NetFlow records include key details such as source and destination IPs, ports, protocol types, and timestamps.

|Field|Description|
|--:|:--|
|`SrcAddr`|Source IP address|
|`DstAddr`|Destination IP address|
|`SrcPort`|Source port number|
|`DstPort`|Destination port number|
|`Protocol`|Transport protocol (TCP, UDP, etc.)|
|`Packets`|Number of packets in the flow|
|`Bytes`|Total bytes transferred|
|`StartTime`|Timestamp of the first packet in the flow|
|`EndTime`|Timestamp of the last packet in the flow|
|`SrcAS`|Source Autonomous System (AS) number|
|`DstAS`|Destination Autonomous System (AS) number|
|`TCPFlags`|TCP control flags for the flow|
|`ToS`|Type of Service (QoS marking)|
|`NextHop`|IP address of the next hop router|
|`FlowDuration`|Duration of the flow in milliseconds|

This is a general overview; actual fields may vary depending on the versions and implementations.

### sFlow

sFlow (Sampled Flow) is a network monitoring protocol designed for high-speed networks. Unlike NetFlow and IPFIX, which capture complete flow records, sFlow uses packet sampling to provide scalable and efficient traffic analysis. It operates by embedding monitoring agents in network devices that randomly sample packets and send them to a central collector for analysis.  

|Field|Description|
|--:|:--|
|`sampleSequenceNumber`|Unique identifier for the sampled packet|
|`sourceIP`|Source IP address|
|`destinationIP`|Destination IP address|
|`sourcePort`|Source port number|
|`destinationPort`|Destination port number|
|`protocol`|Transport protocol (TCP, UDP, etc.)|
|`sampledPacketSize`|Size of the sampled packet in bytes|
|`inputInterface`|Interface where the packet was received|
|`outputInterface`|Interface where the packet was forwarded|
|`vlanID`|VLAN identifier of the packet|
|`tcpFlags`|TCP control flags|
|`flowSampleType`|Type of sampling (e.g., packet, counter)|
|`samplingRate`|Ratio of sampled packets to total packets|
|`agentAddress`|IP address of the device performing sampling|
|`collectorAddress`|IP address of the sFlow collector|

sFlow's lightweight sampling approach makes it ideal for real-time traffic monitoring in large-scale, high-speed networks.

## Pattern Matching

### Grok Patterns

Common patterns used in log processing:

|Category|Patterns|
|--:|:--|
|General|`DATA` `GREEDYDATA` `NOTSPACE` `SPACE` `WORD`|
|Numeric|`BASE10NUM` `INT` `NUMBER`|
|Networking|`HOSTNAME` `IP` `IPV4` `IPV6` `MAC`|
|Data and Time|`DATESTAMP` `DATESTAMP_RFC822` `TIMESTAMP_ISO8601`|
|File System|`FILENAME` `PATH`|
|HTTP|`HTTPDATE` `HTTPDERRORLOG` `HTTPDUSER`|
|System|`SYSLOGBASE` `SYSLOGHOST` `SYSLOGTIMESTAMP`|
|Other|`EMAILADDRESS` `URIPARAM` `URIPATH` `UUID`|

### Metadata Tags

Common metadata fields used in log processing:

|Field|Subfields|
|--:|:--|
|`_ingest`|`on_failure_processor_tag` `on_failure_processor_type`|
|`_temp`|`observer.mac`|
|`destination`|`bytes` `domain` `ip` `nat.port` `port` `user.domain` `name`|
|`email`|`from.address` `to.address`|
|`event`|`category` `kind` `original` `outcome` `type`|
|`source`|`bytes` `ip` `user.domain` `group.name` `id` `xlatesrc`|
|`observer`|`product` `type` `vendor`|
|`related`|`hash` `ip`|

## File Formats

### Parquet Files

Apache Parquet is a column-oriented storage format designed for efficiency:

**Row-based storage** (traditional):

```plaintext
id,name,last_name,age
1,John,Buck,35
2,Jane,Doe,27
3,Joe,Dane,42
```

**Column-based Storage** (Parquet):

```plaintext
id:1,2,3
name:John,Jane,Joe
last_name:Buck,Doe,Dane
age:35,27,42
```

Key features:

- Dictionary encoding
- Compressing and bit packing
- Run-length encoding
- Optimal for columnar queries

### PEM Files

Privacy Enhanced Mail (PEM) files are used for storing cryptographic keys and certificates:

```encoding
---BEGIN CERTIFICATE---
MIIHzTCCBbWgAwIBAgIQaBYE3/M08XHYCnNVmcFBcjANBgkqhkiG9w0BAQsFADBy
...
---END CERTIFICATE---
```

Common uses:

- SSL/TLS certificates
- SSH keys
- RSA private keys
- Certificate chains

File characteristics:

- Base64-encoded content
- Begin/end markers
- Can contain multiple certificates/keys
- Text-based format

## Protocols

### Syslog

Standard protocol for system logging with severity levels:

|Level|Severity|Description|
|:-:|:--|:--|
|`0`|Emergency|System unusable|
|`1`|Alert|Immediate action required|
|`2`|Critical|Condition critical|
|`3`|Error|Errors exist|
|`4`|Warning|Warnings exist|
|`5`|Notice|Significant condition|
|`6`|Info|Info messages|
|`7`|Debug|Debug messages|

The protocol is used for:

- System health monitoring
- Performance monitoring
- Security event logging
- Compliance tracking
