# Appendix

## ASIM

The _Advanced Security Information Model_ is a layer between the data and the user to configure what and how to ingest data from a source and to route it to a destination.

For details, see [this article](https://learn.microsoft.com/en-us/azure/sentinel/normalization).

Available ASIM tables:

> `ASimAuditEventLogs` `ASimAuthenticationEventLogs` `ASimDhcpEventLogs` `ASimDnsActivityLogs` `ASimFileEventLogs` `ASimNetworkSessionLogs` `ASimProcessEventLogs` `ASimRegistryEventLogs` `ASimUserManagementActivityLogs`

## CEF

The _Common Event Format_ is a standardized security event logging layout. Its creator is _ArcSight_, and it has been widely adpoted by the industry. It has a header followed by extension fields, and a standard prefix with 7 required fields. It supports an extensible _key-value_ pair format. 

## CIM

The _Common Information Model_ (CIM) is a standardized data model developed by **Splunk**.

Its purpose is to normalize diverse log data into a consistent format across different data sources and use cases. It provides a shared semantic framework that makes it easier to correlate and analyze data from various systems, applications, and security tools by mapping raw log fields to standardized field names and data types. This standardization enables organizations to build searches, alerts, and dashboards that work consistently regardless of the underlying data sources.

### Common Fields

| Field Category | Fields | Description |
|---------------|---------|-------------|
| Base Fields | `source`, `sourcetype`, `timestamp`, `host`, `index` | Core fields for event identification and source tracking |
| Identity Fields | `user`, `src_user`, `dest_user` | User identification and authentication tracking |
| Network Fields | `src_ip`, `dest_ip`, `src_port`, `dest_port` | Network communication endpoints |

### Data Models

| Model Type | Fields | Purpose |
|------------|--------|----------|
| Authentication | `action`, `app`, `status`, `auth_method` | Track authentication events and access control |
| Network Traffic | `bytes`, `protocol`, `direction`, `tcp_flags` | Monitor network communications and traffic patterns |
| Vulnerability | `severity`, `signature`, `vulnerability_id` | Track security vulnerabilities and risks |
| Changes | - | Track system and configuration changes |
| Intrusion Detection | - | Monitor security threats and intrusions |

### Event Categories

| Category | Event Types | Description |
|----------|-------------|-------------|
| Authentication | `success`, `failure`, `logout` | Authentication-related events and outcomes |
| Network | `connection`, `alert`, `traffic` | Network activity and communications |
| System | `change`, `status`, `error` | System-level events and status changes |
| Security | - | Security-related events and alerts |

## ECS

_Elastic Common Schema_ (ECS) is a specification that defines a common set of fields for ingesting data into _Elasticsearch_. It provides a unified structure for various types of data like logs, metrics, and traces, making it easier to correlate data across different sources and use cases. ECS standardizes field names, types, and meanings across all data types, enabling consistent data analysis and visualization in Elasticsearch and Kibana.

Key features of ECS include standardized field sets for common security and observability use cases, nested field groups for complex data relationships, and strict field naming conventions that help prevent naming conflicts while maintaining clarity.

| Field Group | Core Fields | Description |
|-------------|-------------|-------------|
| Base Fields | `@timestamp`, `tags`, `labels`, `message` | Universal fields that appear in every event |
| Host | `host.name`, `host.ip`, `host.os.*`, `host.mac` | Information about the host machine |
| Network | `network.protocol`, `network.type`, `network.direction`, `network.bytes` | Network activity details |
| Source/Destination | `source.ip`, `source.port`, `dest.ip`, `dest.port` | Communication endpoint information |
| User | `user.id`, `user.name`, `user.domain`, `user.email` | User-related information |
| Event | `event.category`, `event.type`, `event.action`, `event.outcome` | Event classification details |
| File | `file.path`, `file.size`, `file.type`, `file.hash.*` | File-related information |
| Process | `process.pid`, `process.name`, `process.args`, `process.parent.*` | Process execution details |
| Error | `error.code`, `error.message`, `error.type`, `error.stack_trace` | Error-related information |
| Trace | `trace.id`, `span.id`, `transaction.id` | Distributed tracing data |

## Grok Patterns

The grok patterns used by **Director**'s selection process:

|Category|Patterns|
|---|---|
|General|`DATA` `GREEDYDATA` `NOTSPACE` `SPACE` `WORD`|
|Numeric|`BASE10NUM` `INT` `NUMBER`|
|Networking|`HOSTNAME` `IP` `IPV4` `IPV6` `MAC`|
|Data and Time|`DATESTAMP` `DATESTAMP_RFC822` `TIMESTAMP_ISO8601`|
|File System|`FILENAME` `PATH`|
|HTTP|`HTTPDATE` `HTTPDERRORLOG` `HTTPDUSER`|
|System|`SYSLOGBASE` `SYSLOGHOST` `SYSLOGTIMESTAMP`|
|Other|`EMAILADDRESS` `URIPARAM` `URIPATH` `UUID`|

## LEEF

The _Log Event Extended Format_ is an enterprise security event logging format. It was created by _IBM QRadar_. Its parsing requirements are lightweight. It has fixed header with 

- `version`
- `vendor`
- `product`
- `version`
- `eventID`

This is followed by a variable attributes section. The format is optimized for SIEM processing.

## Metadata Tags

The metadata tags used by **Director**'s ingestion process:

|Field|Subfields|
|---|---|
|`_ingest`|`on_failure_processor_tag` `on_failure_processor_type`|
|`_temp`|`observer.mac`|
|`destination`|`bytes` `domain` `ip` `nat.port` `port` `user.domain` `name`|
|`email`|`from.address` `to.address`|
|`event`|`category` `kind` `original` `outcome` `type`|
|`source`|`bytes` `ip` `user.domain` `group.name` `id` `xlatesrc`|
|`observer`|`product` `type` `vendor`|
|`related`|`hash` `ip`|
|`vendor`|`__nsons` `__p_dport` `__pos` `_conf` `_ingest` `_temp` `_temp_` `action` `administrator` `bcc` `cc` `client_inbound_bytes` `client_inbound_packets` `client_ip` `client_outbound_bytes` `client_outbound_bytes` `client_outbound_packets` `contextnum` `destination_dns_hostname` `device_name` `device_type` `dst` `dst_machine_name` `dst_user_dn` `dst_user_name` `endpoint_ip` `file_size` `from` `hll_key` `ifname` `lastupdatetime` `mac_source_address` `operation` `operation_number` `origin_ip` `product` `product` `received_bytes` `received_bytes` `s_port` `s_port` `segment_time` `sent_byte` `sequencenum` `server_inbound_bytes` `server_inbound_packets` `server_outbound_bytes` `server_outbound_bytes` `server_outbound_interface` `server_outbound_packets` `server_outbound_packets` `service` `severity` `src` `src_machine_name` `src_user_group` `src_user_name` `subs_exp` `syslog5424_ts` `tags` `time` `to` `uid` `uid` `xlatedport` `xlatedst` `xlatedst` `xlatesport` `xlatesport` `xlatesrc` `xlatesrc`|

## Parquet Files

The parquet file was designed by Apache as a column-based format. Unlike row-based formats like CSV, it stores the records in columns.

**Row-based storage** First row contains field names:

```plaintext
id,name,last_name,age
1,John,Buck,35
2,Jane,Doe,27
3,Joe,Dane,42
```

**Column-based Storage** First column contains field names:

```plaintext
id:1,2,3
name:John,Jane,Joe
last_name:Buck,Doe,Dane
age:35, 27,42
```

Parquet files use _dictionary encoding_, compression and _bit packing_, and _run-length encoding_, features which make it more efficient compared to row-based formats.

## PEM Files

A _Privacy Enhanced Mail_ file is a container format often used to store cryptographic keys, certificates, and other data. It is a base64-encoded file that starts with a header and ends with a footer, e.g.:

```encoding
-----BEGIN CERTIFICATE-----
MIIH/TCCBeWgAwIBAgIQaBYE3/M08XHYCnNVmcFBcjANBgkqhkiG9w0BAQsFADBy
MQswCQYDVQQGEwJVUzEOMAwGA1UECAwFVGV4YXMxEDAOBgNVBAcMB0hvdXN0b24x
ETAPBgNVBAoMCFNTTCBDb3JwMS4wLAYDVQQDDCVTU0wuY29tIEVWIFNTTCBJbnRl
cm1lZGlhdGUgQ0EgUlNBIFIzMB4XDTIwMDQwMTAwNTgzM1oXDTIxMDcxNjAwNTgz
M1owgb0xCzAJBgNVBAYTAlVTMQ4wDAYDVQQIDAVUZXhhczEQMA4GA1UEBwwHSG91
...
-----END CERTIFICATE-----
```

where `CERTIFICATE` can also be `PRIVATE KEY` or `RSA KEY`. These blocks communicate what is encoded in the file.

This is a text-based format, and the base64-encoded data can be uppercase and lowercase letters, digits, '+', and '/'.

A **PEM** file can contain multiple blocks of such data. These are generally used to encode for example **RSA** keys for **SSH** connections, certificates used for **SSL** encryption and the keys associated with them, etc.

A **PEM** file for certificates can specify

* the end-user certificate assigned to a domain name by a **CA** (Certificate Authority)
* up to 4 intermedidate certificates
* a root certificate self-signed by the **CA**

These are generally issued by the **SSL** provider to be used in a web service.

**PEM** files are also used for **SSH**. Typical use on the command line is:

```CLI-linux
ssh -i keyfile.pem root@host
```

where the `-i` parameter specifies the PEM file to use to create a secure **SSH** connection `host`.

## Syslog

**SYSLOG** is a standard protocol used for system logging in computer networks. Using this protocol, devices and applications send log messages to central servers that store them for monitoring and analysis.

**Syslog** has numeric severity levels, indicating their importance. The lower the value, the more critical the event. The levels are used for:

* _Prioritization_ of critical issues
* _Filtering_ of log messages
* _Automation_ of specific types of events
* _Compliance_ with regulatory standards

|Level|Severity|Description|
|---|---|---|
|0|Emergency|System unusable|
|1|Alert|Immediate action required|
|2|Critical|Condition critical|
|3|Error|Errors exist|
|4|Warning|Warnings exist|
|5|Notice|Significant condition|
|6|Info|Info messages|
|7|Debug|Debug messages|
