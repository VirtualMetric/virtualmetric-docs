---
sidebar_label: From Cribl
---

# Migrating from Cribl to DataStream

This guide provides step-by-step instructions for migrating your existing Cribl Stream or Cribl Edge deployment to DataStream.

## Feature Comparison

| Feature | Cribl | DataStream |
|---------|-------|------------|
| Configuration Format | YAML/JSON | YAML |
| Functions/Pipelines | Functions, Pipelines, Routes | Processors, Pipelines |
| Sources | Sources | Devices |
| Destinations | Destinations | Outputs |
| Deployment Model | Leader/Worker or Standalone | Distributed or Standalone |
| Management | Leader UI or API | Configuration Files or API |

## Configuration Mapping

### Sources to Devices

Cribl sources can be mapped to DataStream devices as follows:

| Cribl Source | DataStream Device |
|--------------|-------------------|
| HTTP | HTTP |
| Syslog | Syslog |
| TCP | TCP |
| UDP | UDP |
| Windows Event Logs | Windows |
| Azure Monitor | Azure Monitor |
| Kafka | Kafka (coming soon) |

### Functions to Processors

Cribl functions can be mapped to DataStream processors:

| Cribl Function | DataStream Processor |
|----------------|----------------------|
| Eval | Script |
| Rename | Rename |
| Drop | Remove |
| Parser (CSV) | CSV |
| Parser (JSON) | JSON |
| Parser (Regex) | Grok |
| Parser (Key-Value) | KV |

### Routes to Pipelines

Cribl routes are conceptually similar to DataStream pipelines. In DataStream, define clear processing paths with conditional branching where needed.

### Destinations to Outputs

Cribl destinations can be mapped to DataStream outputs:

| Cribl Destination | DataStream Output |
|-------------------|-------------------|
| AWS S3 | S3 |
| Elasticsearch | Elasticsearch |
| Splunk | Splunk |
| HTTP | HTTP |
| Kafka | Kafka (coming soon) |

## Migration Steps

1. **Inventory Your Cribl Deployment**
   - Document all sources, destinations, and pipelines
   - Note any custom JavaScript functions or expressions

2. **Create Device Configurations**
   - Convert Cribl sources to DataStream devices
   - Example: Convert HTTP source to HTTP device

   ```yaml
   # Cribl HTTP Source
   {
     "id": "http_in",
     "type": "http",
     "host": "0.0.0.0",
     "port": 10080,
     "authType": "none"
   }
   
   # DataStream HTTP Device
   - id: 1
     name: http_in
     type: http
     properties:
       address: "0.0.0.0"
       port: 10080
   ```

3. **Create Processor Configurations**
   - Map Cribl functions to DataStream processors
   - Example: Convert Eval function to Script processor

   ```yaml
   # Cribl Eval Function
   {
     "id": "set_source",
     "filter": "true",
     "disabled": false,
     "conf": {
       "add": [
         {
           "name": "source",
           "value": "'cribl_http'"
         }
       ]
     }
   }
   
   # DataStream Script Processor
   - set:
     - field: source
     - value: "cribl_http"
   ```

4. **Create Output Configurations**
   - Convert Cribl destinations to DataStream outputs
   - Adapt any routing logic to DataStream's pipeline model

5. **Test Configuration**
   - Deploy configuration in a test environment
   - Validate data flows through the system as expected
   - Compare output with original Cribl deployment

6. **Deploy in Production**
   - Set up parallel ingestion to both systems
   - Gradually shift traffic to DataStream
   - Verify metrics and logs are properly processed

## Configuration Examples

### Complex Pipeline Conversion

```yaml
# Cribl Pipeline (simplified JSON)
{
  "id": "main",
  "functions": [
    {
      "id": "eval",
      "conf": {
        "add": [{"name": "meta_source", "value": "'cribl'"}]
      }
    },
    {
      "id": "parser",
      "filter": "true",
      "conf": {
        "type": "kv",
        "srcField": "message"
      }
    }
  ]
}

# DataStream Pipeline
pipelines:
  - name: main
    processors:
      - set:
        - field: meta_source
        - value: "cribl"
      - kv:
        - field: message
        - field_split: " "
        - value_split: "="
```

## Advanced Considerations

### JavaScript Functions

For custom JavaScript functions in Cribl, use DataStream's Script processor with `lang: golang`:

```yaml
script:
  - lang: golang
    source: |
      package main
      
      func main() {
        // Your conversion of the JavaScript logic
        if val, ok := logEntry["field"].(string); ok {
          logEntry["processed"] = processField(val)
        }
      }
      
      func processField(input string) string {
        // Processing logic here
        return input
      }
```

### Lookup Tables

Convert Cribl lookup tables to DataStream's equivalent format and reference them in your processors.

### Event Breakers

For custom event breaking in Cribl, use DataStream's appropriate framing options in TCP/UDP devices.

## Performance Tuning

After migration, optimize your DataStream deployment:

1. Adjust batch sizes and flush intervals based on throughput requirements
2. Configure appropriate worker counts for devices
3. Enable TLS where security is required
4. Use pipelines to filter data early in the processing chain

## Need Help?

Contact DataStream support for assistance with your migration:
- Submit a support ticket
- Join our community forum
- Schedule a migration consultation with our experts
