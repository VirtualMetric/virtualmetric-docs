---
pagination_prev: null
pagination_next: null
---

# Glossary

## A

<dt>**Agent**</dt>
<dd>A software component installed on systems to collect and forward telemetry data. Can be managed (traditionally installed) or auto-managed (automatically deployed).</dd>

<dt>**Agentless**</dt>
<dd>Collection method that does not require installing software on target systems, typically using existing protocols like SSH or WinRM.</dd>

<dt>**Aggregation**</dt>
<dd>Process of combining and grouping multiple data points based on common properties.</dd>

<dt>**Alert**</dt>
<dd>Notification of significant system events.</dd>

<dt>**Archival**</dt>
<dd>Long-term data storage process.</dd>

<dt>**Audit**</dt>
<dd>Review of logs for the purpose of verifying that IT policies are correctly implemented.</dd>

<dt>**Audit Trail**</dt>
<dd>Records of all system access instances and actions carried out.</dd>

<dt>**Authentication**</dt>
<dd>Verification of the identity of users, devices, or systems attempting to access network resources.</dd>

<dt>**Access Control**</dt>
<dd>A security mechanism that regulates who or what can view, use, or modify resources in a computing environment based on predefined policies and permissions.</dd>

<dt>**Agent-Director Coordination**</dt>
<dd>Enterprise architecture where lightweight Agents receive centralized configuration from Directors via websocket connections, enabling large-scale network management without per-endpoint configuration.</dd>

<dt>**Authorization**</dt>
<dd>Permission to access specific resources.</dd>
<dd>Enterprise architecture where lightweight Agents receive centralized configuration from Directors via websocket connections, enabling large-scale network management without per-endpoint configuration.</dd>

## B

<dt>**Batch Processing**</dt>
<dd>Collective sequential processing of a large number of records that require the same operations.</dd>

<dt>**Bandwidth**</dt>
<dd>Data transmission capacity per unit time.</dd>

<dt>**Baseline**</dt>
<dd>Reference values for normal operation used for comparison across multiple cases.</dd>

<dt>**Buffer**</dt>
<dd>Temporary storage for telemetry data.</dd>

<dt>**Buffer Management**</dt>
<dd>Control of memory buffers used for temporary data storage during processing, including size control and flush intervals.</dd>

## C

<dt>**Cache**</dt>
<dd>Fast-access temporary data storage.</dd>

<dt>**Consumer**</dt>
<dd>External system that receives processed telemetry data from **DataStream** targets, such as analytics platforms, archival systems, or compliance tools.</dd>

<dt>**Content Hub**</dt>
<dd>Pre-built pipeline templates and business scenarios that provide ready-made processing logic for common telemetry use cases, eliminating the need for custom configuration development.</dd>

<dt>**Calibration**</dt>
<dd>Measurement accuracy adjustment.</dd>

<dt>**Cost Optimization**</dt>
<dd>Strategic configuration of telemetry processing to minimize data processing costs by selecting only business-essential data fields and avoiding expensive operations on unnecessary data.</dd>

<dt>**Collector**</dt>
<dd>System component that receives and processes telemetry data.</dd>

<dt>**Compression**</dt>
<dd>Data size reduction technique used for saving storage space.</dd>

<dt>**Connection Pooling**</dt>
<dd>Maintaining a cache of database connections that can be reused when future requests to the database are required, reducing the overhead of creating new database connections for each request.</dd>

<dt>**Checkpoint Recovery**</dt>
<dd>Using periodic snapshots (checkpoints) of the database state to restore system consistency after a failure by only needing to replay transactions that occurred after the most recent checkpoint.</dd>

## D

<dt>**Dashboard**</dt>
<dd>Visual interface for telemetry data display.</dd>

<dt>**Data Collection Rules (DCR)**</dt>
<dd>Configuration settings that define how data should be collected and processed in Azure Monitor.</dd>

<dt>**Data Enrichment**</dt>
<dd>The process of enhancing data with additional context or information from external sources.</dd>

<dt>**Data Retention Period**</dt>
<dd>Duration for which telemetry data is stored.</dd>

<dt>**Data Resolution**</dt>
<dd>Level of detail used in measurements.</dd>

<dt>**Data Partitioning**</dt>
<dd>Dividing a large dataset into smaller, more manageable sections. Frequently used in parallel computing and distributed systems to improve performance and scalability.</dd>

<dt>**Data Point**</dt>
<dd>Single measurement at a specific time.</dd>

<dt>**Diagnostics**</dt>
<dd>System health monitoring tools and methods.</dd>

<dt>**Device**</dt>
<dd>A source of log data, which can be physical hardware, virtual machines, or software components.</dd>

<dt>**Director**</dt>
<dd>Central orchestration service (vmetric-director.exe) that runs telemetry processing pipelines and coordinates Agent configuration across enterprise networks.</dd>

## E

<dt>**Encryption**</dt>
<dd>Data security achieved through encoding of data to render it unreadable by humans.</dd>

<dt>**Event**</dt>
<dd>Any occurrence in a computerized and networked system that registers as a sender or receiver of signals.</dd>

## F

<dt>**Failover**</dt>
<dd>System backup activation process used in case of emergencies when a hardware resources becomes unusable.</dd>

<dt>**Field Mapping**</dt>
<dd>The process of translating field names from one format to another during data normalization.</dd>

<dt>**Flow**</dt>
<dd>A sequence of related packets in network traffic, typically representing a single connection or transaction.</dd>

<dt>**Fleet Management**</dt>
<dd>Centralized management system for coordinating multiple Directors and Agents across enterprise networks with hierarchical configuration distribution.</dd>

<dt>**Flow Record**</dt>
<dd>Network traffic data record containing connection details, typically from NetFlow, sFlow, or IPFIX protocols used for network monitoring and analysis.</dd>

## G

<dt>**Gateway**</dt>
<dd>Interface between different network segments.</dd>

<dt>**Geohash**</dt>
<dd>A system for encoding geographic locations into short strings of letters and numbers.</dd>

<dt>**Generator**</dt>
<dd>A **Director** mode that produces raw telemetry data sent to **DataStream** devices, such as log collectors, network monitors, or user activity trackers.</dd>

<dt>**Geotile**</dt>
<dd>A method of dividing geographic areas into tiles based on zoom levels and coordinates.</dd>

## H

<dt>**Heartbeat**</dt>
<dd>Periodic signal sent to confirm system operation.</dd>

<dt>**Historical Data**</dt>
<dd>Previously collected measurements.</dd>

## I

<dt>**Ingestion**</dt>
<dd>Collection of data from a source for a specific purpose of use such as analysis or monitoring.</dd>

## L

<dt>**Latency**</dt>
<dd>Time delay in data transmission.</dd>

<dt>**Load Balancing**</dt>
<dd>Distribution of processing load among multiple hardware resources.</dd>

<dt>**Logging**</dt>
<dd>Recording of system events.</dd>

## M

<dt>**Management**</dt>
<dd>The policy implemented to handle log lines after they have been processed.</dd>

<dt>**Metrics**</dt>
<dd>Quantifiable measurements of system attributes.</dd>

<dt>**MIB (Management Information Base)**</dt>
<dd>Definition files for network object structures used for automated management.</dd>

<dt>**Multi-Worker Architecture**</dt>
<dd>Design pattern where multiple worker processes handle tasks concurrently for improved performance.</dd>

## N

<dt>**NetFlow Template**</dt>
<dd>Data structure definition for NetFlow records that describes the format and fields contained in network flow data.</dd>

<dt>**Node**</dt>
<dd>Individual point in a telemetry network.</dd>

<dt>**Normalization**</dt>
<dd>The process of transforming data formats with the intention of rendering them more suitable for use by a consumer.</dd>

## O

<dt>**OID (Object Identifier)**</dt>
<dd>Unique identifiers for network objects in a MIB.</dd>

## P

<dt>**Parser**</dt>
<dd>Component that separates parts of raw data into semantic units.</dd>

<dt>**Payload**</dt>
<dd>Actual data content being transmitted.</dd>

<dt>**Pipeline**</dt>
<dd>Pre-configured processing logic for a data stream.</dd>

<dt>**Polling Interval**</dt>
<dd>Time between consecutive data collection attempts.</dd>

<dt>**Processor**</dt>
<dd>A component that performs a specific operation on streaming data.</dd>

<dt>**Postprocessing**</dt>
<dd>Stage 5 of **DataStream** processing where pipeline output is converted to target-specific formats with schema enforcement and compression optimization.</dd>

<dt>**Predefined Definitions**</dt>
<dd>Ready-made collection patterns for common data sources (such as Windows security events) that Directors provide to Agents, eliminating manual configuration requirements.</dd>

<dt>**Preprocessing**</dt>
<dd>Stage 2 of **DataStream** processing where device-specific formats are transformed to standardized pipeline input using VMFL binary encoding.</dd>

<dt>**Protocol**</dt>
<dd>Rules governing data communication and exchange.</dd>

## Q

<dt>**Query**</dt>
<dd>Request for specific telemetry information.</dd>

## R

<dt>**Real-time Monitoring**</dt>
<dd>Immediate observation of system state and events.</dd>

<dt>**Redundancy**</dt>
<dd>Backup systems used for reliability.</dd>

<dt>**Resource Management**</dt>
<dd>Control and optimization of system resources (CPU, memory, disk) during data processing.</dd>

<dt>**RBAC (Role-Based Access Control)**</dt>
<dd>Access management based on user roles.</dd>

<dt>**Route**</dt>
<dd>YAML orchestration configuration that connects devices, pipelines, and targets to create complete data flow processing chains for specific business purposes.</dd>

<dt>**Routing**</dt>
<dd>Sending or directing a data stream to a destination for further processing or analysis.</dd>

## S

<dt>**Sampling Rate**</dt>
<dd>Frequency at which measurements are taken.</dd>

<dt>**Schema Evolution**</dt>
<dd>Gradual change over time of the layout and structure of data underlying a processing system.</dd>

<dt>**Schema Validation**</dt>
<dd>The process of verifying that data conforms to a predefined structure, format, and rules (schema) before it is processed or stored in a system.</dd>

<dt>**Size-Based Rotation**</dt>
<dd>The practice of automatically creating new log/data files when the current file reaches a specified size limit, helping to manage storage and prevent individual files from becoming too large to handle efficiently.</dd>

<dt>**SNMP (Simple Network Management Protocol)**</dt>
<dd>Standard protocol for network monitoring.</dd>

<dt>**Socket Reuse**</dt>
<dd>Optimization technique allowing multiple processes to share network sockets for improved performance.</dd>

<dt>**Store-and-Forward**</dt>
<dd>A technique where data is temporarily stored locally before being transmitted, ensuring data preservation during network issues.</dd>

<dt>**Supervisor**</dt>
<dd>The component that checks the health of the processes. It restarts stopped services, cleans up the `temp` folder, etc.</dd>

<dt>**Seven-Stage Processing Flow**</dt>
<dd>Complete **DataStream** architecture: Producer → Device → Preprocessing → Pipeline → Postprocessing → Target → Consumer.</dd>

<dt>**Synchronization**</dt>
<dd>Alignment of time-based data.</dd>

## T

<dt>**Telemetry**</dt>
<dd>Remote measurement and data collection system.</dd>

<dt>**Template**</dt>
<dd>Container object with selection and/or processing logic for incoming data stream.</dd>

<dt>**Threshold**</dt>
<dd>Predefined lower limit that triggers alerts or actions.</dd>

<dt>**Timestamp**</dt>
<dd>Time marker associated with collected data.</dd>

<dt>**Time Series**</dt>
<dd>Data points collected over sequential time periods.</dd>

<dt>**TLS (Transport Layer Security)**</dt>
<dd>Cryptographic protocol providing secure communication over networks.</dd>

<dt>**Topology**</dt>
<dd>Network structure and connections. Used to describe the characteristics of and the relations between components.</dd>

<dt>**Target**</dt>
<dd>Data output destination that forwards processed telemetry to external consumers such as analytics platforms, cloud services, or compliance systems.</dd>

<dt>**Trend Analysis**</dt>
<dd>Study of data patterns over time.</dd>

## V

<dt>**Validation**</dt>
<dd>Data accuracy verification.</dd>

<dt>**Vectorized Processing**</dt>
<dd>Using all available cores in a system to load balance the processing operation.</dd>

<dt>**VIP (Variable Information Period)**</dt>
<dd>Configurable time interval for data sampling.</dd>

<dt>**VMFL (VirtualMetric Flow Language)**</dt>
<dd>Binary encoding format used internally for high-performance data ingestion and processing between **DataStream** pipeline stages.</dd>

<dt>**VMF**</dt>
<dd>Binary configuration file format (.vmf) used by Agents to store device configurations received from Directors.</dd>

<dt>**VMMQ**</dt>
<dd>VirtualMetric Message Queue system built on NATS JetStream for enterprise-grade inter-service communication and configuration coordination.</dd>
